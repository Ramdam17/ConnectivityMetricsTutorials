{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a8fb7d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction â€” The Directionality Question\n",
    "\n",
    "So far, all our connectivity measures have been **symmetric**:\n",
    "\n",
    "- **Correlation**: $r(X, Y) = r(Y, X)$\n",
    "- **PLV**: $PLV(X, Y) = PLV(Y, X)$\n",
    "- **Mutual Information**: $I(X; Y) = I(Y; X)$\n",
    "\n",
    "But real relationships are often **directional**!\n",
    "\n",
    "### Examples of Directional Influence\n",
    "\n",
    "- ðŸŽ“ Teacher speaks â†’ Student listens\n",
    "- ðŸ‘¥ Leader acts â†’ Follower responds\n",
    "- ðŸ§  Brain region A drives â†’ Brain region B responds\n",
    "\n",
    "### The Key Question\n",
    "\n",
    "> Does X **influence** Y, or does Y **influence** X, or both?\n",
    "\n",
    "### Enter Transfer Entropy\n",
    "\n",
    "**Transfer Entropy (TE)** measures directed information flow:\n",
    "\n",
    "> *\"How much does knowing X's PAST help predict Y's FUTURE?\"*\n",
    "\n",
    "This is critical for hyperscanning: **who influences whom** during social interaction?\n",
    "\n",
    "ðŸ’¡ **Key insight**: Transfer entropy answers: Does information FLOW from X to Y?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae9caf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "from typing import Tuple, Optional, Dict\n",
    "from scipy import signal\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import sys\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from src.colors import COLORS\n",
    "from src.plotting import configure_plots\n",
    "from src.information import (\n",
    "    compute_entropy_continuous,\n",
    "    compute_mutual_information,\n",
    "    compute_joint_entropy\n",
    ")\n",
    "\n",
    "configure_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587ca9b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Intuition â€” Prediction and Causality\n",
    "\n",
    "### A Thought Experiment: Weather Prediction\n",
    "\n",
    "Imagine you want to predict **tomorrow's weather** in your city:\n",
    "\n",
    "1. **Using only your city's past weather** â†’ Some accuracy\n",
    "2. **Adding the neighboring city's past weather** â†’ Better accuracy?\n",
    "\n",
    "If adding the neighbor's data improves prediction, then:\n",
    "- Information **flows** from the neighbor to your city\n",
    "- The neighbor's weather contains **predictive information** about yours\n",
    "\n",
    "### Wiener-Granger Causality (1956, 1969)\n",
    "\n",
    "> \"X **Granger-causes** Y if X's past helps predict Y's future, **beyond** Y's past alone\"\n",
    "\n",
    "âš ï¸ **Important**: This is not true causality! It's **predictive influence**.\n",
    "\n",
    "### Transfer Entropy = Information-Theoretic Granger Causality\n",
    "\n",
    "| Granger Causality | Transfer Entropy |\n",
    "|-------------------|------------------|\n",
    "| Linear regression | Mutual Information |\n",
    "| Assumes linearity | No linearity assumption |\n",
    "| F-test for significance | Captures nonlinear influences |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Conceptual diagram of prediction improvement\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Predict Y from Y's past only\n",
    "ax = axes[0]\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "# Y's past\n",
    "ax.add_patch(plt.Rectangle((1, 3), 3, 4, color=COLORS[\"signal_2\"], alpha=0.7))\n",
    "ax.text(2.5, 5, \"Y past\", ha=\"center\", va=\"center\", fontsize=14, fontweight=\"bold\", color=\"white\")\n",
    "\n",
    "# Y's future (with uncertainty)\n",
    "ax.add_patch(plt.Rectangle((6, 3), 3, 4, color=COLORS[\"signal_2\"], alpha=0.3))\n",
    "ax.add_patch(plt.Rectangle((6.5, 3.5), 2, 3, color=COLORS[\"signal_2\"], alpha=0.5))\n",
    "ax.text(7.5, 5, \"Y future\\n(uncertain)\", ha=\"center\", va=\"center\", fontsize=12)\n",
    "\n",
    "# Arrow\n",
    "ax.annotate(\"\", xy=(6, 5), xytext=(4, 5),\n",
    "            arrowprops=dict(arrowstyle=\"->\", lw=3, color=\"black\"))\n",
    "ax.text(5, 5.8, \"Predict\", ha=\"center\", fontsize=11)\n",
    "\n",
    "ax.set_title(\"Prediction from Y's past only\", fontsize=14, fontweight=\"bold\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Right: Predict Y from Y's past AND X's past\n",
    "ax = axes[1]\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "# X's past\n",
    "ax.add_patch(plt.Rectangle((1, 6), 3, 2.5, color=COLORS[\"signal_1\"], alpha=0.7))\n",
    "ax.text(2.5, 7.25, \"X past\", ha=\"center\", va=\"center\", fontsize=14, fontweight=\"bold\", color=\"white\")\n",
    "\n",
    "# Y's past\n",
    "ax.add_patch(plt.Rectangle((1, 2), 3, 2.5, color=COLORS[\"signal_2\"], alpha=0.7))\n",
    "ax.text(2.5, 3.25, \"Y past\", ha=\"center\", va=\"center\", fontsize=14, fontweight=\"bold\", color=\"white\")\n",
    "\n",
    "# Y's future (less uncertainty!)\n",
    "ax.add_patch(plt.Rectangle((6, 3), 3, 4, color=COLORS[\"signal_2\"], alpha=0.3))\n",
    "ax.add_patch(plt.Rectangle((6.8, 4), 1.4, 2, color=COLORS[\"signal_2\"], alpha=0.8))\n",
    "ax.text(7.5, 5, \"Y future\\n(less uncertain!)\", ha=\"center\", va=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Arrows\n",
    "ax.annotate(\"\", xy=(6, 5), xytext=(4, 3.25),\n",
    "            arrowprops=dict(arrowstyle=\"->\", lw=2, color=COLORS[\"signal_2\"]))\n",
    "ax.annotate(\"\", xy=(6, 5), xytext=(4, 7.25),\n",
    "            arrowprops=dict(arrowstyle=\"->\", lw=3, color=COLORS[\"signal_1\"]))\n",
    "\n",
    "ax.text(5, 7, \"Extra info!\", ha=\"center\", fontsize=11, color=COLORS[\"signal_1\"], fontweight=\"bold\")\n",
    "\n",
    "ax.set_title(\"Prediction from BOTH pasts â€” TE measures this improvement!\", fontsize=14, fontweight=\"bold\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ Transfer Entropy = How much X's past REDUCES uncertainty about Y's future\")\n",
    "print(\"   (beyond what Y's own past already tells us)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceda668",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. From Mutual Information to Transfer Entropy\n",
    "\n",
    "### The Problem with MI\n",
    "\n",
    "Mutual Information $I(X; Y)$ measures shared information between **current** values.\n",
    "\n",
    "But it ignores **time**! We want to know about **prediction**.\n",
    "\n",
    "### The Solution: Consider Past and Future\n",
    "\n",
    "**Notation**:\n",
    "- $X_{past}$ = history of X: $X(t-\\tau), X(t-2\\tau), ...$\n",
    "- $Y_{past}$ = history of Y: $Y(t-\\tau), Y(t-2\\tau), ...$  \n",
    "- $Y_{future}$ = what we want to predict: $Y(t)$\n",
    "\n",
    "### Transfer Entropy Definition\n",
    "\n",
    "$$TE_{X \\to Y} = I(Y_{future}; X_{past} \\mid Y_{past})$$\n",
    "\n",
    "Read as: *\"Information that X's past provides about Y's future, **given** Y's past\"*\n",
    "\n",
    "This is **conditional mutual information** â€” the information gained BEYOND what Y's past already tells us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2830a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Timeline diagram showing embedding for TE\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Time axis\n",
    "ax.set_xlim(0, 14)\n",
    "ax.set_ylim(0, 8)\n",
    "\n",
    "# Draw X signal timeline\n",
    "y_x = 6\n",
    "ax.plot([1, 13], [y_x, y_x], 'k-', linewidth=2)\n",
    "ax.text(0.5, y_x, \"X\", fontsize=16, fontweight=\"bold\", va=\"center\", color=COLORS[\"signal_1\"])\n",
    "\n",
    "# X past samples\n",
    "for i, t in enumerate([3, 5, 7]):\n",
    "    ax.plot(t, y_x, 'o', markersize=15, color=COLORS[\"signal_1\"])\n",
    "    ax.text(t, y_x + 0.5, f\"t-{3-i}Ï„\" if i < 2 else \"t-Ï„\", ha=\"center\", fontsize=10)\n",
    "\n",
    "# X past bracket\n",
    "ax.annotate(\"\", xy=(2.5, y_x - 0.3), xytext=(7.5, y_x - 0.3),\n",
    "            arrowprops=dict(arrowstyle=\"<->\", color=COLORS[\"signal_1\"], lw=2))\n",
    "ax.text(5, y_x - 0.8, \"$X_{past}$\", ha=\"center\", fontsize=14, color=COLORS[\"signal_1\"], fontweight=\"bold\")\n",
    "\n",
    "# Draw Y signal timeline\n",
    "y_y = 3\n",
    "ax.plot([1, 13], [y_y, y_y], 'k-', linewidth=2)\n",
    "ax.text(0.5, y_y, \"Y\", fontsize=16, fontweight=\"bold\", va=\"center\", color=COLORS[\"signal_2\"])\n",
    "\n",
    "# Y past samples\n",
    "for i, t in enumerate([3, 5, 7]):\n",
    "    ax.plot(t, y_y, 'o', markersize=15, color=COLORS[\"signal_2\"])\n",
    "\n",
    "# Y past bracket  \n",
    "ax.annotate(\"\", xy=(2.5, y_y - 0.3), xytext=(7.5, y_y - 0.3),\n",
    "            arrowprops=dict(arrowstyle=\"<->\", color=COLORS[\"signal_2\"], lw=2))\n",
    "ax.text(5, y_y - 0.8, \"$Y_{past}$\", ha=\"center\", fontsize=14, color=COLORS[\"signal_2\"], fontweight=\"bold\")\n",
    "\n",
    "# Y future (target)\n",
    "ax.plot(10, y_y, 's', markersize=20, color=COLORS[\"signal_3\"], zorder=5)\n",
    "ax.text(10, y_y + 0.6, \"$Y_{future}$\", ha=\"center\", fontsize=14, color=COLORS[\"signal_3\"], fontweight=\"bold\")\n",
    "ax.text(10, y_y - 0.6, \"t\", ha=\"center\", fontsize=12)\n",
    "\n",
    "# Arrows showing information flow\n",
    "ax.annotate(\"\", xy=(9.5, y_y + 0.2), xytext=(7.5, y_y),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=COLORS[\"signal_2\"], lw=2, ls=\"--\"))\n",
    "ax.annotate(\"\", xy=(9.5, y_y + 0.3), xytext=(7.5, y_x - 0.5),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=COLORS[\"signal_1\"], lw=3))\n",
    "\n",
    "# Labels\n",
    "ax.text(8.5, 4.8, \"TE = Extra\\ninfo from X!\", fontsize=12, color=COLORS[\"signal_1\"], \n",
    "        fontweight=\"bold\", ha=\"center\")\n",
    "\n",
    "# Time arrow\n",
    "ax.annotate(\"\", xy=(13, 1), xytext=(1, 1),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"gray\", lw=2))\n",
    "ax.text(7, 0.5, \"Time â†’\", ha=\"center\", fontsize=12, color=\"gray\")\n",
    "\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"Transfer Entropy: Information Flow from X's Past to Y's Future\", \n",
    "             fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“Š TE measures how much X's past helps predict Y's future,\")\n",
    "print(\"   BEYOND what Y's own past already provides.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6637c6b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. The Transfer Entropy Formula\n",
    "\n",
    "### Conditional Mutual Information\n",
    "\n",
    "$$I(A; B \\mid C) = H(A \\mid C) - H(A \\mid B, C)$$\n",
    "\n",
    "*\"Information A provides about B, given we already know C\"*\n",
    "\n",
    "### Transfer Entropy Formula\n",
    "\n",
    "$$TE_{X \\to Y} = H(Y_t \\mid Y_{past}) - H(Y_t \\mid Y_{past}, X_{past})$$\n",
    "\n",
    "**Interpretation**:\n",
    "- $H(Y_t \\mid Y_{past})$ = uncertainty about Y's future given **only** Y's past\n",
    "- $H(Y_t \\mid Y_{past}, X_{past})$ = uncertainty given **both** pasts\n",
    "- **TE** = reduction in uncertainty from adding X's information\n",
    "\n",
    "### Key Properties\n",
    "\n",
    "| Property | Meaning |\n",
    "|----------|---------|\n",
    "| $TE \\geq 0$ | Adding information can't hurt prediction |\n",
    "| $TE = 0$ | X provides no additional predictive power |\n",
    "| $TE_{X \\to Y} \\neq TE_{Y \\to X}$ | **Asymmetric!** (unlike MI) |\n",
    "| Units: bits | (when using $\\log_2$) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Venn diagram for conditional MI / Transfer Entropy\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "# Three circles: Y_future, Y_past, X_past\n",
    "r = 2.0\n",
    "\n",
    "# Positions (overlapping)\n",
    "c_yfut = Circle((0, 0), r, fill=False, edgecolor=COLORS[\"signal_3\"], linewidth=3, label=\"$Y_{future}$\")\n",
    "c_ypast = Circle((-1.5, -1.5), r, fill=False, edgecolor=COLORS[\"signal_2\"], linewidth=3, label=\"$Y_{past}$\")\n",
    "c_xpast = Circle((1.5, -1.5), r, fill=False, edgecolor=COLORS[\"signal_1\"], linewidth=3, label=\"$X_{past}$\")\n",
    "\n",
    "ax.add_patch(c_yfut)\n",
    "ax.add_patch(c_ypast)\n",
    "ax.add_patch(c_xpast)\n",
    "\n",
    "# Labels\n",
    "ax.text(0, 1.5, \"$Y_{future}$\", ha=\"center\", fontsize=14, fontweight=\"bold\", color=COLORS[\"signal_3\"])\n",
    "ax.text(-3, -2.5, \"$Y_{past}$\", ha=\"center\", fontsize=14, fontweight=\"bold\", color=COLORS[\"signal_2\"])\n",
    "ax.text(3, -2.5, \"$X_{past}$\", ha=\"center\", fontsize=14, fontweight=\"bold\", color=COLORS[\"signal_1\"])\n",
    "\n",
    "# Highlight TE region (Y_future âˆ© X_past \\ Y_past)\n",
    "# This is simplified - just annotate the concept\n",
    "ax.annotate(\"TE\", xy=(0.7, -0.3), fontsize=20, fontweight=\"bold\", color=\"red\",\n",
    "            ha=\"center\", va=\"center\")\n",
    "ax.annotate(\"\", xy=(0.7, -0.5), xytext=(1.2, -1.2),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2))\n",
    "\n",
    "# Explanation text\n",
    "ax.text(0, -4.5, \n",
    "        \"$TE_{Xâ†’Y} = I(Y_{future}; X_{past} | Y_{past})$\\n\"\n",
    "        \"= Information X's past shares with Y's future,\\n\"\n",
    "        \"that Y's past doesn't already provide\",\n",
    "        ha=\"center\", fontsize=12, style=\"italic\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"lightyellow\", alpha=0.8))\n",
    "\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-6, 4)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"Transfer Entropy as Conditional Mutual Information\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb80f08",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Implementing Transfer Entropy\n",
    "\n",
    "### Steps to Compute TE\n",
    "\n",
    "1. **Define embedding parameters**:\n",
    "   - $k$ = history length for Y (how many past samples)\n",
    "   - $l$ = history length for X\n",
    "   - $\\tau$ = time delay between samples\n",
    "\n",
    "2. **Create state vectors**:\n",
    "   - $Y_{past}$ = $[Y(t-\\tau), Y(t-2\\tau), ..., Y(t-k\\tau)]$\n",
    "   - $X_{past}$ = $[X(t-\\tau), X(t-2\\tau), ..., X(t-l\\tau)]$\n",
    "   - $Y_{future}$ = $Y(t)$\n",
    "\n",
    "3. **Estimate entropies** via binning or KNN\n",
    "\n",
    "4. **Compute TE** = $H(Y_t | Y_{past}) - H(Y_t | Y_{past}, X_{past})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b219329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_vectors(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    k: int = 1,\n",
    "    l: int = 1,\n",
    "    tau: int = 1\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create embedded state vectors for Transfer Entropy computation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Source signal.\n",
    "    y : np.ndarray\n",
    "        Target signal.\n",
    "    k : int\n",
    "        History length for target (Y). Default is 1.\n",
    "    l : int\n",
    "        History length for source (X). Default is 1.\n",
    "    tau : int\n",
    "        Embedding delay in samples. Default is 1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y_future : np.ndarray\n",
    "        Target values at time t, shape (n_valid,).\n",
    "    y_past : np.ndarray\n",
    "        Target history vectors, shape (n_valid, k).\n",
    "    x_past : np.ndarray\n",
    "        Source history vectors, shape (n_valid, l).\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    \n",
    "    # Maximum lookback needed\n",
    "    max_lag = max(k, l) * tau\n",
    "    \n",
    "    # Valid indices (where we have full history)\n",
    "    n_valid = n - max_lag\n",
    "    \n",
    "    # Initialize arrays\n",
    "    y_future = np.zeros(n_valid)\n",
    "    y_past = np.zeros((n_valid, k))\n",
    "    x_past = np.zeros((n_valid, l))\n",
    "    \n",
    "    for i in range(n_valid):\n",
    "        idx = i + max_lag  # Current time index\n",
    "        \n",
    "        # Y future (target)\n",
    "        y_future[i] = y[idx]\n",
    "        \n",
    "        # Y past (k samples)\n",
    "        for j in range(k):\n",
    "            y_past[i, j] = y[idx - (j + 1) * tau]\n",
    "        \n",
    "        # X past (l samples)\n",
    "        for j in range(l):\n",
    "            x_past[i, j] = x[idx - (j + 1) * tau]\n",
    "    \n",
    "    return y_future, y_past, x_past\n",
    "\n",
    "\n",
    "# Quick test\n",
    "np.random.seed(42)\n",
    "x_test = np.random.randn(100)\n",
    "y_test = np.random.randn(100)\n",
    "\n",
    "y_fut, y_past, x_past = create_embedding_vectors(x_test, y_test, k=2, l=2, tau=1)\n",
    "print(f\"Input length: {len(x_test)}\")\n",
    "print(f\"Output shapes: y_future={y_fut.shape}, y_past={y_past.shape}, x_past={x_past.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b99d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transfer_entropy(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    k: int = 1,\n",
    "    l: int = 1,\n",
    "    tau: int = 1,\n",
    "    n_bins: int = 8\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute Transfer Entropy from X to Y: TE_{Xâ†’Y}.\n",
    "    \n",
    "    TE_{Xâ†’Y} = H(Y_t | Y_past) - H(Y_t | Y_past, X_past)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Source signal.\n",
    "    y : np.ndarray\n",
    "        Target signal.\n",
    "    k : int\n",
    "        History length for target (Y). Default is 1.\n",
    "    l : int\n",
    "        History length for source (X). Default is 1.\n",
    "    tau : int\n",
    "        Embedding delay in samples. Default is 1.\n",
    "    n_bins : int\n",
    "        Number of bins per dimension for histogram. Default is 8.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Transfer entropy from X to Y in bits.\n",
    "    \"\"\"\n",
    "    # Create embedding vectors\n",
    "    y_future, y_past, x_past = create_embedding_vectors(x, y, k, l, tau)\n",
    "    \n",
    "    n_samples = len(y_future)\n",
    "    \n",
    "    # Discretize all variables\n",
    "    def discretize(arr: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Discretize array into bins.\"\"\"\n",
    "        if arr.ndim == 1:\n",
    "            arr = arr.reshape(-1, 1)\n",
    "        \n",
    "        result = np.zeros(arr.shape, dtype=int)\n",
    "        for col in range(arr.shape[1]):\n",
    "            # Use percentile-based binning for robustness\n",
    "            percentiles = np.linspace(0, 100, n_bins + 1)\n",
    "            bin_edges = np.percentile(arr[:, col], percentiles)\n",
    "            result[:, col] = np.digitize(arr[:, col], bin_edges[1:-1])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # Discretize\n",
    "    y_fut_d = discretize(y_future).flatten()\n",
    "    y_past_d = discretize(y_past)\n",
    "    x_past_d = discretize(x_past)\n",
    "    \n",
    "    # Convert multi-dimensional indices to single index\n",
    "    def to_single_index(arr: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Convert multi-column discrete array to single index.\"\"\"\n",
    "        if arr.ndim == 1:\n",
    "            return arr\n",
    "        result = np.zeros(len(arr), dtype=int)\n",
    "        multiplier = 1\n",
    "        for col in range(arr.shape[1] - 1, -1, -1):\n",
    "            result += arr[:, col] * multiplier\n",
    "            multiplier *= n_bins\n",
    "        return result\n",
    "    \n",
    "    y_past_idx = to_single_index(y_past_d)\n",
    "    x_past_idx = to_single_index(x_past_d)\n",
    "    \n",
    "    # Combined index for (y_past, x_past)\n",
    "    yx_past_idx = y_past_idx * (n_bins ** l) + x_past_idx\n",
    "    \n",
    "    # Compute entropies using histogram counts\n",
    "    def entropy_from_joint(idx1: np.ndarray, idx2: np.ndarray) -> float:\n",
    "        \"\"\"Compute H(idx1 | idx2) = H(idx1, idx2) - H(idx2).\"\"\"\n",
    "        # Joint entropy H(idx1, idx2)\n",
    "        joint = np.ravel_multi_index((idx1, idx2), (idx1.max() + 1, idx2.max() + 1))\n",
    "        _, joint_counts = np.unique(joint, return_counts=True)\n",
    "        p_joint = joint_counts / n_samples\n",
    "        H_joint = -np.sum(p_joint * np.log2(p_joint + 1e-12))\n",
    "        \n",
    "        # Marginal entropy H(idx2)\n",
    "        _, marginal_counts = np.unique(idx2, return_counts=True)\n",
    "        p_marginal = marginal_counts / n_samples\n",
    "        H_marginal = -np.sum(p_marginal * np.log2(p_marginal + 1e-12))\n",
    "        \n",
    "        return H_joint - H_marginal\n",
    "    \n",
    "    # H(Y_t | Y_past)\n",
    "    H_y_given_ypast = entropy_from_joint(y_fut_d, y_past_idx)\n",
    "    \n",
    "    # H(Y_t | Y_past, X_past)\n",
    "    H_y_given_yxpast = entropy_from_joint(y_fut_d, yx_past_idx)\n",
    "    \n",
    "    # Transfer Entropy\n",
    "    te = H_y_given_ypast - H_y_given_yxpast\n",
    "    \n",
    "    # TE should be non-negative\n",
    "    return max(0.0, te)\n",
    "\n",
    "\n",
    "# Test with independent signals (TE should be ~0)\n",
    "np.random.seed(42)\n",
    "x_indep = np.random.randn(2000)\n",
    "y_indep = np.random.randn(2000)\n",
    "\n",
    "te_indep = compute_transfer_entropy(x_indep, y_indep, k=1, l=1, tau=1)\n",
    "print(f\"TE for independent signals: {te_indep:.4f} bits (should be ~0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb057a8a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Example â€” Coupled Signals\n",
    "\n",
    "Let's test TE on signals where we **know** the ground truth:\n",
    "- X drives Y with some delay\n",
    "- Y does NOT drive X\n",
    "\n",
    "We expect:\n",
    "- $TE_{X \\to Y} > 0$ (X influences Y)\n",
    "- $TE_{Y \\to X} \\approx 0$ (Y doesn't influence X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbf323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coupled_signals(\n",
    "    n_samples: int,\n",
    "    coupling_x_to_y: float = 0.5,\n",
    "    coupling_y_to_x: float = 0.0,\n",
    "    delay_samples: int = 5,\n",
    "    noise_level: float = 0.3,\n",
    "    seed: Optional[int] = None\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate coupled AR-like signals with specified directional coupling.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        Number of samples to generate.\n",
    "    coupling_x_to_y : float\n",
    "        Coupling strength from X to Y (0 to 1). Default is 0.5.\n",
    "    coupling_y_to_x : float\n",
    "        Coupling strength from Y to X (0 to 1). Default is 0.0.\n",
    "    delay_samples : int\n",
    "        Delay in samples for the coupling. Default is 5.\n",
    "    noise_level : float\n",
    "        Standard deviation of noise. Default is 0.3.\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x : np.ndarray\n",
    "        Source signal (or first signal if bidirectional).\n",
    "    y : np.ndarray\n",
    "        Target signal (or second signal if bidirectional).\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Initialize signals\n",
    "    x = np.zeros(n_samples)\n",
    "    y = np.zeros(n_samples)\n",
    "    \n",
    "    # Generate AR(1) base processes\n",
    "    ar_coef = 0.7\n",
    "    \n",
    "    for t in range(1, n_samples):\n",
    "        # Autoregressive component\n",
    "        x[t] = ar_coef * x[t-1] + noise_level * np.random.randn()\n",
    "        y[t] = ar_coef * y[t-1] + noise_level * np.random.randn()\n",
    "        \n",
    "        # Coupling X â†’ Y\n",
    "        if t >= delay_samples and coupling_x_to_y > 0:\n",
    "            y[t] += coupling_x_to_y * x[t - delay_samples]\n",
    "        \n",
    "        # Coupling Y â†’ X\n",
    "        if t >= delay_samples and coupling_y_to_x > 0:\n",
    "            x[t] += coupling_y_to_x * y[t - delay_samples]\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Generate unidirectionally coupled signals (X â†’ Y)\n",
    "x_coupled, y_coupled = generate_coupled_signals(\n",
    "    n_samples=3000,\n",
    "    coupling_x_to_y=0.5,\n",
    "    coupling_y_to_x=0.0,\n",
    "    delay_samples=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Generated coupled signals: X â†’ Y (unidirectional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e789166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 4: Coupled signals and TE asymmetry\n",
    "\n",
    "# Compute TE in both directions\n",
    "te_x_to_y = compute_transfer_entropy(x_coupled, y_coupled, k=1, l=1, tau=5)\n",
    "te_y_to_x = compute_transfer_entropy(y_coupled, x_coupled, k=1, l=1, tau=5)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Top left: X signal\n",
    "ax = axes[0, 0]\n",
    "ax.plot(x_coupled[:500], color=COLORS[\"signal_1\"], linewidth=0.8)\n",
    "ax.set_title(\"Signal X (driver)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Samples\")\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Top right: Y signal  \n",
    "ax = axes[0, 1]\n",
    "ax.plot(y_coupled[:500], color=COLORS[\"signal_2\"], linewidth=0.8)\n",
    "ax.set_title(\"Signal Y (driven by X)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Samples\")\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom left: Scatter plot\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(x_coupled[:-5], y_coupled[5:], alpha=0.3, s=5, color=COLORS[\"signal_3\"])\n",
    "ax.set_xlabel(\"X(t)\", fontsize=12)\n",
    "ax.set_ylabel(\"Y(t+5)\", fontsize=12)\n",
    "ax.set_title(\"X predicts future Y (5 samples later)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom right: TE bar chart\n",
    "ax = axes[1, 1]\n",
    "bars = ax.bar([\"TE: X â†’ Y\", \"TE: Y â†’ X\"], [te_x_to_y, te_y_to_x], \n",
    "              color=[COLORS[\"signal_1\"], COLORS[\"signal_2\"]], width=0.5)\n",
    "ax.set_ylabel(\"Transfer Entropy (bits)\", fontsize=12)\n",
    "ax.set_title(\"TE Correctly Detects Direction!\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, [te_x_to_y, te_y_to_x]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "            f\"{val:.3f}\", ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "ax.set_ylim(0, max(te_x_to_y, te_y_to_x) * 1.3)\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Results:\")\n",
    "print(f\"   TE(X â†’ Y) = {te_x_to_y:.4f} bits  â† X DOES influence Y\")\n",
    "print(f\"   TE(Y â†’ X) = {te_y_to_x:.4f} bits  â† Y does NOT influence X\")\n",
    "print(f\"\\nâœ… TE correctly identifies the unidirectional coupling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0222803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 5: TE scales with coupling strength\n",
    "\n",
    "coupling_strengths = np.linspace(0, 0.8, 9)\n",
    "te_values = []\n",
    "\n",
    "for coupling in coupling_strengths:\n",
    "    x, y = generate_coupled_signals(\n",
    "        n_samples=3000,\n",
    "        coupling_x_to_y=coupling,\n",
    "        coupling_y_to_x=0.0,\n",
    "        delay_samples=5,\n",
    "        seed=42\n",
    "    )\n",
    "    te = compute_transfer_entropy(x, y, k=1, l=1, tau=5)\n",
    "    te_values.append(te)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(coupling_strengths, te_values, \"o-\", color=COLORS[\"signal_1\"], \n",
    "        linewidth=2.5, markersize=10)\n",
    "ax.fill_between(coupling_strengths, te_values, alpha=0.3, color=COLORS[\"signal_1\"])\n",
    "\n",
    "ax.set_xlabel(\"Coupling Strength (X â†’ Y)\", fontsize=12)\n",
    "ax.set_ylabel(\"Transfer Entropy (bits)\", fontsize=12)\n",
    "ax.set_title(\"TE Increases with Coupling Strength\", fontsize=14, fontweight=\"bold\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ TE scales monotonically with the true coupling strength!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad1d24f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Bidirectional Coupling and Net TE\n",
    "\n",
    "Real systems often have **bidirectional coupling** â€” both signals influence each other.\n",
    "\n",
    "TE can detect both directions:\n",
    "- $TE_{X \\to Y} > 0$ AND $TE_{Y \\to X} > 0$\n",
    "\n",
    "### Net Transfer Entropy\n",
    "\n",
    "$$Net_{X \\to Y} = TE_{X \\to Y} - TE_{Y \\to X}$$\n",
    "\n",
    "| Net TE | Interpretation |\n",
    "|--------|----------------|\n",
    "| Positive | X dominates (more influence Xâ†’Y) |\n",
    "| Negative | Y dominates (more influence Yâ†’X) |\n",
    "| â‰ˆ Zero | Balanced bidirectional coupling |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5753a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_net_transfer_entropy(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    k: int = 1,\n",
    "    l: int = 1,\n",
    "    tau: int = 1,\n",
    "    n_bins: int = 8\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute TE in both directions and net flow.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        First signal.\n",
    "    y : np.ndarray\n",
    "        Second signal.\n",
    "    k, l, tau, n_bins : int\n",
    "        TE parameters.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Contains 'te_x_to_y', 'te_y_to_x', 'net_te', 'dominant_direction'.\n",
    "    \"\"\"\n",
    "    te_x_to_y = compute_transfer_entropy(x, y, k, l, tau, n_bins)\n",
    "    te_y_to_x = compute_transfer_entropy(y, x, k, l, tau, n_bins)\n",
    "    net_te = te_x_to_y - te_y_to_x\n",
    "    \n",
    "    if net_te > 0.01:\n",
    "        dominant = \"X â†’ Y\"\n",
    "    elif net_te < -0.01:\n",
    "        dominant = \"Y â†’ X\"\n",
    "    else:\n",
    "        dominant = \"Balanced\"\n",
    "    \n",
    "    return {\n",
    "        \"te_x_to_y\": te_x_to_y,\n",
    "        \"te_y_to_x\": te_y_to_x,\n",
    "        \"net_te\": net_te,\n",
    "        \"dominant_direction\": dominant\n",
    "    }\n",
    "\n",
    "\n",
    "# Generate bidirectionally coupled signals\n",
    "x_bidir, y_bidir = generate_coupled_signals(\n",
    "    n_samples=3000,\n",
    "    coupling_x_to_y=0.5,  # X influences Y\n",
    "    coupling_y_to_x=0.2,  # Y also influences X (but less)\n",
    "    delay_samples=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "result = compute_net_transfer_entropy(x_bidir, y_bidir, k=1, l=1, tau=5)\n",
    "\n",
    "print(\"ðŸ“Š Bidirectional Coupling Analysis:\")\n",
    "print(f\"   TE(X â†’ Y) = {result['te_x_to_y']:.4f} bits\")\n",
    "print(f\"   TE(Y â†’ X) = {result['te_y_to_x']:.4f} bits\")\n",
    "print(f\"   Net TE    = {result['net_te']:.4f} bits\")\n",
    "print(f\"   Dominant  = {result['dominant_direction']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e696b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 6: Net TE as function of coupling strength ratio\n",
    "\n",
    "def generate_simple_coupled_signals(\n",
    "    n_samples: int,\n",
    "    coupling_x_to_y: float,\n",
    "    coupling_y_to_x: float,\n",
    "    delay: int = 5,\n",
    "    seed: int = 42\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate simple coupled signals without feedback loops.\n",
    "    Uses independent noise sources with lagged coupling.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # Independent noise sources\n",
    "    noise_x = rng.randn(n_samples)\n",
    "    noise_y = rng.randn(n_samples)\n",
    "    \n",
    "    # X = noise + AR component\n",
    "    x = np.zeros(n_samples)\n",
    "    for t in range(1, n_samples):\n",
    "        x[t] = 0.7 * x[t-1] + 0.5 * noise_x[t]\n",
    "    \n",
    "    # Y = noise + AR component + coupling from X (lagged)\n",
    "    y = np.zeros(n_samples)\n",
    "    for t in range(1, n_samples):\n",
    "        y[t] = 0.7 * y[t-1] + 0.5 * noise_y[t]\n",
    "        if t >= delay:\n",
    "            y[t] += coupling_x_to_y * x[t - delay]\n",
    "    \n",
    "    # Now add Yâ†’X coupling (using a separate pass to avoid feedback loop)\n",
    "    if coupling_y_to_x > 0:\n",
    "        x_coupled = x.copy()\n",
    "        for t in range(delay, n_samples):\n",
    "            x_coupled[t] += coupling_y_to_x * y[t - delay]\n",
    "        x = x_coupled\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Symmetric progression of coupling values\n",
    "# Each condition has a clear difference from the previous one\n",
    "coupling_values = [\n",
    "    (0.6, 0.0),   # Only Xâ†’Y (strong)\n",
    "    (0.6, 0.2),   # Xâ†’Y dominant\n",
    "    (0.4, 0.4),   # Balanced\n",
    "    (0.2, 0.6),   # Yâ†’X dominant\n",
    "    (0.0, 0.6),   # Only Yâ†’X (strong)\n",
    "]\n",
    "\n",
    "labels = [\"Xâ†’Y\\nonly\", \"Xâ†’Y\\ndominant\", \"Balanced\", \"Yâ†’X\\ndominant\", \"Yâ†’X\\nonly\"]\n",
    "\n",
    "net_te_values = []\n",
    "te_xy_values = []\n",
    "te_yx_values = []\n",
    "\n",
    "for i, (c_xy, c_yx) in enumerate(coupling_values):\n",
    "    x, y = generate_simple_coupled_signals(\n",
    "        n_samples=5000,\n",
    "        coupling_x_to_y=c_xy,\n",
    "        coupling_y_to_x=c_yx,\n",
    "        delay=5,\n",
    "        seed=42 + i  # Different seed per condition\n",
    "    )\n",
    "    \n",
    "    result = compute_net_transfer_entropy(x, y, k=1, l=1, tau=5, n_bins=10)\n",
    "    te_xy_values.append(result[\"te_x_to_y\"])\n",
    "    te_yx_values.append(result[\"te_y_to_x\"])\n",
    "    net_te_values.append(result[\"net_te\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "x_pos = np.arange(len(coupling_values))\n",
    "\n",
    "# Left: Both TEs as grouped bars\n",
    "ax = axes[0]\n",
    "width = 0.35\n",
    "bars1 = ax.bar(x_pos - width/2, te_xy_values, width, color=COLORS[\"signal_1\"], label=\"TE: X â†’ Y\")\n",
    "bars2 = ax.bar(x_pos + width/2, te_yx_values, width, color=COLORS[\"signal_2\"], label=\"TE: Y â†’ X\")\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels, fontsize=10)\n",
    "ax.set_ylabel(\"Transfer Entropy (bits)\", fontsize=12)\n",
    "ax.set_title(\"TE in Both Directions\", fontsize=12, fontweight=\"bold\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Right: Net TE\n",
    "ax = axes[1]\n",
    "colors = [COLORS[\"signal_1\"] if v > 0 else COLORS[\"signal_2\"] for v in net_te_values]\n",
    "bars = ax.bar(x_pos, net_te_values, color=colors, alpha=0.7, edgecolor=\"black\", linewidth=1.5)\n",
    "ax.axhline(y=0, color=COLORS[\"grid\"], linestyle=\"--\", linewidth=2)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels, fontsize=10)\n",
    "ax.set_ylabel(\"Net TE (Xâ†’Y minus Yâ†’X)\", fontsize=12)\n",
    "ax.set_title(\"Net TE Indicates Dominant Direction\", fontsize=12, fontweight=\"bold\")\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Add annotations\n",
    "ax.annotate(\"X dominates\", xy=(0.1, 0.85), xycoords=\"axes fraction\", fontsize=10, \n",
    "            color=COLORS[\"signal_1\"], fontweight=\"bold\")\n",
    "ax.annotate(\"Y dominates\", xy=(0.7, 0.15), xycoords=\"axes fraction\", fontsize=10,\n",
    "            color=COLORS[\"signal_2\"], fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the coupling values used\n",
    "print(\"Coupling configurations:\")\n",
    "for label, (c_xy, c_yx) in zip(labels, coupling_values):\n",
    "    print(f\"  {label.replace(chr(10), ' ')}: Xâ†’Y = {c_xy}, Yâ†’X = {c_yx}\")\n",
    "print()\n",
    "print(\"ðŸ’¡ Net TE correctly identifies the dominant information flow direction!\")\n",
    "print(f\"   â€¢ Xâ†’Y only:     Net TE = {net_te_values[0]:+.3f} (positive)\")\n",
    "print(f\"   â€¢ Balanced:     Net TE = {net_te_values[2]:+.3f} (near zero)\")\n",
    "print(f\"   â€¢ Yâ†’X only:     Net TE = {net_te_values[-1]:+.3f} (negative)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992c189",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Parameter Selection\n",
    "\n",
    "Computing TE requires choosing several **embedding parameters**:\n",
    "\n",
    "| Parameter | Symbol | What it controls |\n",
    "|-----------|--------|------------------|\n",
    "| **Y history length** | $k$ | How many past values of Y to consider |\n",
    "| **X history length** | $l$ | How many past values of X to consider |\n",
    "| **Embedding delay** | $\\tau$ | Time spacing between past values |\n",
    "| **Number of bins** | `n_bins` | Discretization resolution |\n",
    "\n",
    "### Guidelines for Parameter Selection\n",
    "\n",
    "**Embedding delay (Ï„)**:\n",
    "- Should match the expected influence timescale\n",
    "- For neural signals: typically 10-100 ms\n",
    "- Too short: captures autocorrelation, not coupling\n",
    "- Too long: misses the causal relationship\n",
    "\n",
    "**History lengths (k, l)**:\n",
    "- Start simple: k = l = 1\n",
    "- Increase if system has longer memory\n",
    "- More history = higher dimensionality = need MORE data!\n",
    "\n",
    "**Number of bins**:\n",
    "- Same trade-off as for MI\n",
    "- Too few: poor resolution\n",
    "- Too many: sparse histograms, high bias\n",
    "\n",
    "**Critical constraint**: Total dimensions $(k + l + 1) \\times n\\_bins$ should be $\\ll n\\_samples$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12115800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 7: Effect of embedding delay (Ï„) on TE\n",
    "\n",
    "# Generate signals with known delay\n",
    "true_delay = 8  # True coupling delay in samples\n",
    "\n",
    "x_delayed, y_delayed = generate_coupled_signals(\n",
    "    n_samples=5000,\n",
    "    coupling_x_to_y=0.5,\n",
    "    coupling_y_to_x=0.0,\n",
    "    delay_samples=true_delay,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Scan over different Ï„ values\n",
    "tau_values = np.arange(1, 20)\n",
    "te_vs_tau = []\n",
    "\n",
    "for tau in tau_values:\n",
    "    te = compute_transfer_entropy(x_delayed, y_delayed, k=1, l=1, tau=tau, n_bins=8)\n",
    "    te_vs_tau.append(te)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.plot(tau_values, te_vs_tau, \"o-\", color=COLORS[\"signal_1\"], linewidth=2, markersize=8)\n",
    "ax.axvline(x=true_delay, color=COLORS[\"signal_4\"], linestyle=\"--\", linewidth=2, \n",
    "           label=f\"True delay = {true_delay}\")\n",
    "ax.set_xlabel(\"Embedding Delay Ï„ (samples)\", fontsize=12)\n",
    "ax.set_ylabel(\"Transfer Entropy (bits)\", fontsize=12)\n",
    "ax.set_title(\"TE Peaks at the True Coupling Delay\", fontsize=12, fontweight=\"bold\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find peak\n",
    "peak_tau = tau_values[np.argmax(te_vs_tau)]\n",
    "print(f\"ðŸ’¡ TE peaks at Ï„ = {peak_tau} samples (true delay = {true_delay})\")\n",
    "print(\"   Scanning Ï„ can help identify the coupling timescale!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f9228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 8: Effect of history length (k) on TE\n",
    "\n",
    "k_values = [1, 2, 3, 4, 5]\n",
    "te_vs_k = []\n",
    "te_vs_k_indep = []  # For independent signals (should stay low)\n",
    "\n",
    "# Independent signals for comparison\n",
    "np.random.seed(123)\n",
    "x_ind = np.random.randn(5000)\n",
    "y_ind = np.random.randn(5000)\n",
    "\n",
    "for k in k_values:\n",
    "    # Coupled signals\n",
    "    te_coupled = compute_transfer_entropy(x_delayed, y_delayed, k=k, l=1, tau=true_delay, n_bins=6)\n",
    "    te_vs_k.append(te_coupled)\n",
    "    \n",
    "    # Independent signals\n",
    "    te_ind = compute_transfer_entropy(x_ind, y_ind, k=k, l=1, tau=1, n_bins=6)\n",
    "    te_vs_k_indep.append(te_ind)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.bar(np.array(k_values) - 0.15, te_vs_k, width=0.3, color=COLORS[\"signal_1\"], \n",
    "       label=\"Coupled signals\", alpha=0.8)\n",
    "ax.bar(np.array(k_values) + 0.15, te_vs_k_indep, width=0.3, color=COLORS[\"signal_2\"],\n",
    "       label=\"Independent signals\", alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(\"History Length k\", fontsize=12)\n",
    "ax.set_ylabel(\"Transfer Entropy (bits)\", fontsize=12)\n",
    "ax.set_title(\"Effect of History Length on TE\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xticks(k_values)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ Observations:\")\n",
    "print(\"   â€¢ For coupled signals: TE is relatively stable (the relationship exists)\")\n",
    "print(\"   â€¢ For independent signals: TE increases with k (bias from dimensionality!)\")\n",
    "print(\"   â€¢ Higher k = more dimensions = more spurious patterns = higher bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835496c0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Bias and Significance Testing\n",
    "\n",
    "As we saw above, TE suffers from **positive bias**, especially with:\n",
    "- Higher dimensions (larger k, l)\n",
    "- Fewer bins (undersampled histograms)\n",
    "- Limited data\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Even for **completely independent** signals, TE will be positive!\n",
    "\n",
    "This is because we're estimating high-dimensional joint distributions from finite data.\n",
    "\n",
    "### The Solution: Surrogate Testing\n",
    "\n",
    "1. **Generate surrogates**: Shuffle the source signal X (destroys Xâ†’Y relationship)\n",
    "2. **Compute TE on surrogates**: This gives the \"null\" TE (bias only)\n",
    "3. **Compare**: Observed TE vs null distribution\n",
    "4. **Effective TE**: $TE_{eff} = TE_{observed} - \\mathbb{E}[TE_{null}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de86ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_te_surrogate(\n",
    "    x: NDArray[np.float64],\n",
    "    y: NDArray[np.float64],\n",
    "    k: int = 1,\n",
    "    l: int = 1,\n",
    "    tau: int = 1,\n",
    "    n_bins: int = 8,\n",
    "    seed: Optional[int] = None\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute TE with shuffled source signal (null hypothesis).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : NDArray[np.float64]\n",
    "        Source signal (will be shuffled).\n",
    "    y : NDArray[np.float64]\n",
    "        Target signal (kept intact).\n",
    "    k : int\n",
    "        History length for target.\n",
    "    l : int\n",
    "        History length for source.\n",
    "    tau : int\n",
    "        Embedding delay.\n",
    "    n_bins : int\n",
    "        Number of bins for discretization.\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        TE computed on shuffled source (null TE).\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    x_shuffled = rng.permutation(x)\n",
    "    return compute_transfer_entropy(x_shuffled, y, k, l, tau, n_bins)\n",
    "\n",
    "\n",
    "def te_significance_test(\n",
    "    x: NDArray[np.float64],\n",
    "    y: NDArray[np.float64],\n",
    "    k: int = 1,\n",
    "    l: int = 1,\n",
    "    tau: int = 1,\n",
    "    n_bins: int = 8,\n",
    "    n_surrogates: int = 200,\n",
    "    seed: Optional[int] = None\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Test significance of transfer entropy using surrogate distribution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : NDArray[np.float64]\n",
    "        Source signal.\n",
    "    y : NDArray[np.float64]\n",
    "        Target signal.\n",
    "    k : int\n",
    "        History length for target.\n",
    "    l : int\n",
    "        History length for source.\n",
    "    tau : int\n",
    "        Embedding delay.\n",
    "    n_bins : int\n",
    "        Number of bins.\n",
    "    n_surrogates : int\n",
    "        Number of surrogates for null distribution.\n",
    "    seed : int, optional\n",
    "        Random seed.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Contains: te_observed, te_effective, null_mean, null_std, p_value\n",
    "    \"\"\"\n",
    "    # Observed TE\n",
    "    te_observed = compute_transfer_entropy(x, y, k, l, tau, n_bins)\n",
    "    \n",
    "    # Generate null distribution\n",
    "    rng = np.random.RandomState(seed)\n",
    "    null_te = []\n",
    "    for i in range(n_surrogates):\n",
    "        te_null = compute_te_surrogate(x, y, k, l, tau, n_bins, seed=rng.randint(100000))\n",
    "        null_te.append(te_null)\n",
    "    \n",
    "    null_te = np.array(null_te)\n",
    "    null_mean = np.mean(null_te)\n",
    "    null_std = np.std(null_te)\n",
    "    \n",
    "    # Effective TE (bias-corrected)\n",
    "    te_effective = te_observed - null_mean\n",
    "    \n",
    "    # P-value (one-tailed: observed > null)\n",
    "    p_value = np.mean(null_te >= te_observed)\n",
    "    \n",
    "    return {\n",
    "        \"te_observed\": te_observed,\n",
    "        \"te_effective\": te_effective,\n",
    "        \"null_mean\": null_mean,\n",
    "        \"null_std\": null_std,\n",
    "        \"null_distribution\": null_te,\n",
    "        \"p_value\": p_value\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ“ TE significance testing functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 9: Significance testing example\n",
    "\n",
    "# Test on coupled signals\n",
    "result_coupled = te_significance_test(\n",
    "    x_delayed, y_delayed, \n",
    "    k=1, l=1, tau=true_delay, n_bins=8,\n",
    "    n_surrogates=200, seed=42\n",
    ")\n",
    "\n",
    "# Test on independent signals\n",
    "result_indep = te_significance_test(\n",
    "    x_ind, y_ind,\n",
    "    k=1, l=1, tau=1, n_bins=8,\n",
    "    n_surrogates=200, seed=42\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Coupled signals\n",
    "ax = axes[0]\n",
    "ax.hist(result_coupled[\"null_distribution\"], bins=30, color=COLORS[\"signal_2\"], \n",
    "        alpha=0.7, edgecolor=\"white\", label=\"Null distribution\")\n",
    "ax.axvline(result_coupled[\"te_observed\"], color=COLORS[\"signal_1\"], linewidth=3, \n",
    "           label=f\"Observed TE = {result_coupled['te_observed']:.3f}\")\n",
    "ax.axvline(result_coupled[\"null_mean\"], color=COLORS[\"grid\"], linestyle=\"--\", \n",
    "           linewidth=2, label=f\"Null mean = {result_coupled['null_mean']:.3f}\")\n",
    "ax.set_xlabel(\"Transfer Entropy (bits)\", fontsize=12)\n",
    "ax.set_ylabel(\"Count\", fontsize=12)\n",
    "ax.set_title(f\"Coupled Signals (p = {result_coupled['p_value']:.3f})\", \n",
    "             fontsize=12, fontweight=\"bold\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Independent signals\n",
    "ax = axes[1]\n",
    "ax.hist(result_indep[\"null_distribution\"], bins=30, color=COLORS[\"signal_2\"], \n",
    "        alpha=0.7, edgecolor=\"white\", label=\"Null distribution\")\n",
    "ax.axvline(result_indep[\"te_observed\"], color=COLORS[\"signal_1\"], linewidth=3,\n",
    "           label=f\"Observed TE = {result_indep['te_observed']:.3f}\")\n",
    "ax.axvline(result_indep[\"null_mean\"], color=COLORS[\"grid\"], linestyle=\"--\",\n",
    "           linewidth=2, label=f\"Null mean = {result_indep['null_mean']:.3f}\")\n",
    "ax.set_xlabel(\"Transfer Entropy (bits)\", fontsize=12)\n",
    "ax.set_ylabel(\"Count\", fontsize=12)\n",
    "ax.set_title(f\"Independent Signals (p = {result_indep['p_value']:.3f})\", \n",
    "             fontsize=12, fontweight=\"bold\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Results:\")\n",
    "print(f\"   Coupled signals:     TE_eff = {result_coupled['te_effective']:.4f} bits, p = {result_coupled['p_value']:.4f} âœ“ Significant!\")\n",
    "print(f\"   Independent signals: TE_eff = {result_indep['te_effective']:.4f} bits, p = {result_indep['p_value']:.4f} âœ— Not significant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24ff6b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. TE for Neural Signals\n",
    "\n",
    "When applying TE to EEG/neural data, consider:\n",
    "\n",
    "### Preprocessing\n",
    "- **Band-pass filter** to frequency of interest\n",
    "- TE on raw broadband can be noisy\n",
    "- Often compute TE on amplitude envelope or phase\n",
    "\n",
    "### Typical Parameters for EEG\n",
    "| Parameter | Typical Range | Rationale |\n",
    "|-----------|---------------|-----------|\n",
    "| Ï„ | 10-50 ms | Expected neural delay |\n",
    "| k, l | 1-3 | Short memory for oscillations |\n",
    "| n_bins | 6-10 | Balance bias and resolution |\n",
    "\n",
    "### Frequency-Specific TE\n",
    "Different frequency bands may show different information flow patterns:\n",
    "- **Theta** (4-8 Hz): Memory, navigation\n",
    "- **Alpha** (8-13 Hz): Attention, inhibition\n",
    "- **Beta** (13-30 Hz): Motor, coordination\n",
    "- **Gamma** (30+ Hz): Perception, binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c55b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def compute_te_bandlimited(\n",
    "    x: NDArray[np.float64],\n",
    "    y: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: Tuple[float, float],\n",
    "    k: int = 1,\n",
    "    l: int = 1,\n",
    "    tau_ms: float = 20.0,\n",
    "    n_bins: int = 8\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute TE on band-limited signals.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : NDArray[np.float64]\n",
    "        Source signal.\n",
    "    y : NDArray[np.float64]\n",
    "        Target signal.\n",
    "    fs : float\n",
    "        Sampling frequency in Hz.\n",
    "    band : tuple\n",
    "        Frequency band (low_freq, high_freq) in Hz.\n",
    "    k : int\n",
    "        History length for target.\n",
    "    l : int\n",
    "        History length for source.\n",
    "    tau_ms : float\n",
    "        Embedding delay in milliseconds.\n",
    "    n_bins : int\n",
    "        Number of bins.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Transfer entropy on band-limited signals.\n",
    "    \"\"\"\n",
    "    # Design bandpass filter\n",
    "    low, high = band\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(4, [low / nyq, high / nyq], btype=\"band\")\n",
    "    \n",
    "    # Filter signals\n",
    "    x_filt = filtfilt(b, a, x)\n",
    "    y_filt = filtfilt(b, a, y)\n",
    "    \n",
    "    # Convert tau from ms to samples\n",
    "    tau_samples = max(1, int(tau_ms * fs / 1000))\n",
    "    \n",
    "    return compute_transfer_entropy(x_filt, y_filt, k, l, tau_samples, n_bins)\n",
    "\n",
    "\n",
    "# Visualization 10: Band-specific TE\n",
    "\n",
    "# Generate coupled neural-like signals\n",
    "fs = 250  # Hz\n",
    "duration = 20  # seconds\n",
    "n_samples = int(fs * duration)\n",
    "\n",
    "np.random.seed(42)\n",
    "t = np.arange(n_samples) / fs\n",
    "\n",
    "# Create broadband \"neural\" signals with directional coupling in alpha band\n",
    "x_neural = np.random.randn(n_samples)\n",
    "y_neural = np.random.randn(n_samples)\n",
    "\n",
    "# Add alpha oscillation to x\n",
    "alpha_freq = 10  # Hz\n",
    "x_neural += 2 * np.sin(2 * np.pi * alpha_freq * t)\n",
    "\n",
    "# Couple x to y with delay (in alpha band)\n",
    "delay_samples = int(0.02 * fs)  # 20 ms delay\n",
    "for i in range(delay_samples, n_samples):\n",
    "    y_neural[i] += 0.5 * x_neural[i - delay_samples]\n",
    "\n",
    "# Define frequency bands\n",
    "bands = {\n",
    "    \"Theta (4-8 Hz)\": (4, 8),\n",
    "    \"Alpha (8-13 Hz)\": (8, 13),\n",
    "    \"Beta (13-30 Hz)\": (13, 30),\n",
    "    \"Gamma (30-50 Hz)\": (30, 50)\n",
    "}\n",
    "\n",
    "band_colors = [COLORS[\"theta\"], COLORS[\"alpha\"], COLORS[\"beta\"], COLORS[\"gamma\"]]\n",
    "\n",
    "te_per_band = {}\n",
    "for band_name, band_range in bands.items():\n",
    "    te = compute_te_bandlimited(x_neural, y_neural, fs, band_range, \n",
    "                                 k=1, l=1, tau_ms=20.0, n_bins=8)\n",
    "    te_per_band[band_name] = te\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "band_names = list(te_per_band.keys())\n",
    "te_values = list(te_per_band.values())\n",
    "\n",
    "bars = ax.bar(band_names, te_values, color=band_colors, alpha=0.8, edgecolor=\"black\")\n",
    "ax.set_ylabel(\"Transfer Entropy (bits)\", fontsize=12)\n",
    "ax.set_title(\"Frequency-Specific TE (X â†’ Y)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Highlight alpha (where coupling exists)\n",
    "bars[1].set_edgecolor(COLORS[\"signal_4\"])\n",
    "bars[1].set_linewidth(3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ TE is highest in Alpha band â€” where the coupling exists!\")\n",
    "print(\"   This demonstrates frequency-specific information flow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6dc98",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. TE Connectivity Matrix\n",
    "\n",
    "For multi-channel analysis, we compute TE between all pairs of channels.\n",
    "\n",
    "**Key difference from symmetric measures**: The TE matrix is **NOT symmetric**!\n",
    "\n",
    "$$M[i, j] = TE_{i \\to j} \\neq TE_{j \\to i} = M[j, i]$$\n",
    "\n",
    "### Interpretation\n",
    "- **Rows**: Information *senders* (sources)\n",
    "- **Columns**: Information *receivers* (targets)\n",
    "- High row sum â†’ channel broadcasts to many\n",
    "- High column sum â†’ channel receives from many\n",
    "\n",
    "### Net Flow Matrix\n",
    "$$Net[i, j] = TE_{i \\to j} - TE_{j \\to i}$$\n",
    "\n",
    "This is **antisymmetric**: $Net[i, j] = -Net[j, i]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973b3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_te_matrix(\n",
    "    data: NDArray[np.float64],\n",
    "    k: int = 1,\n",
    "    l: int = 1,\n",
    "    tau: int = 1,\n",
    "    n_bins: int = 8\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Compute directed TE matrix for multi-channel data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : NDArray[np.float64]\n",
    "        Multi-channel data of shape (n_channels, n_samples).\n",
    "    k : int\n",
    "        History length for target.\n",
    "    l : int\n",
    "        History length for source.\n",
    "    tau : int\n",
    "        Embedding delay.\n",
    "    n_bins : int\n",
    "        Number of bins.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    NDArray[np.float64]\n",
    "        TE matrix of shape (n_channels, n_channels).\n",
    "        Entry [i, j] = TE from channel i to channel j.\n",
    "        Diagonal is NaN.\n",
    "    \"\"\"\n",
    "    n_channels = data.shape[0]\n",
    "    te_matrix = np.full((n_channels, n_channels), np.nan)\n",
    "    \n",
    "    for i in range(n_channels):\n",
    "        for j in range(n_channels):\n",
    "            if i != j:\n",
    "                te_matrix[i, j] = compute_transfer_entropy(\n",
    "                    data[i], data[j], k, l, tau, n_bins\n",
    "                )\n",
    "    \n",
    "    return te_matrix\n",
    "\n",
    "\n",
    "def compute_net_te_matrix(te_matrix: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Compute net TE matrix from directed TE matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    te_matrix : NDArray[np.float64]\n",
    "        Directed TE matrix from compute_te_matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    NDArray[np.float64]\n",
    "        Net TE matrix: Net[i,j] = TE[i,j] - TE[j,i].\n",
    "        Antisymmetric matrix.\n",
    "    \"\"\"\n",
    "    return te_matrix - te_matrix.T\n",
    "\n",
    "\n",
    "# Visualization 11: TE matrix example\n",
    "\n",
    "# Create 5 channels with known connectivity structure\n",
    "n_channels = 5\n",
    "n_samples = 3000\n",
    "channel_names = [\"Ch1\", \"Ch2\", \"Ch3\", \"Ch4\", \"Ch5\"]\n",
    "\n",
    "np.random.seed(42)\n",
    "data = np.random.randn(n_channels, n_samples)\n",
    "\n",
    "# Add autoregressive structure\n",
    "for ch in range(n_channels):\n",
    "    for t in range(1, n_samples):\n",
    "        data[ch, t] += 0.7 * data[ch, t-1]\n",
    "\n",
    "# Add directional connections:\n",
    "# Ch1 â†’ Ch2 (strong)\n",
    "# Ch1 â†’ Ch3 (moderate)  \n",
    "# Ch4 â†’ Ch5 (strong)\n",
    "delay = 5\n",
    "coupling = 0.6\n",
    "\n",
    "for t in range(delay, n_samples):\n",
    "    data[1, t] += coupling * data[0, t - delay]      # Ch1 â†’ Ch2\n",
    "    data[2, t] += 0.3 * data[0, t - delay]           # Ch1 â†’ Ch3\n",
    "    data[4, t] += coupling * data[3, t - delay]      # Ch4 â†’ Ch5\n",
    "\n",
    "# Compute TE matrix\n",
    "te_mat = compute_te_matrix(data, k=1, l=1, tau=delay, n_bins=8)\n",
    "net_te_mat = compute_net_te_matrix(te_mat)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Directed TE matrix\n",
    "ax = axes[0]\n",
    "im = ax.imshow(te_mat, cmap=\"viridis\", aspect=\"equal\")\n",
    "ax.set_xticks(range(n_channels))\n",
    "ax.set_yticks(range(n_channels))\n",
    "ax.set_xticklabels(channel_names)\n",
    "ax.set_yticklabels(channel_names)\n",
    "ax.set_xlabel(\"Target (receiver)\", fontsize=12)\n",
    "ax.set_ylabel(\"Source (sender)\", fontsize=12)\n",
    "ax.set_title(\"Directed TE Matrix\", fontsize=12, fontweight=\"bold\")\n",
    "plt.colorbar(im, ax=ax, label=\"TE (bits)\")\n",
    "\n",
    "# Right: Net TE matrix\n",
    "ax = axes[1]\n",
    "vmax = np.nanmax(np.abs(net_te_mat))\n",
    "im = ax.imshow(net_te_mat, cmap=\"RdBu_r\", aspect=\"equal\", vmin=-vmax, vmax=vmax)\n",
    "ax.set_xticks(range(n_channels))\n",
    "ax.set_yticks(range(n_channels))\n",
    "ax.set_xticklabels(channel_names)\n",
    "ax.set_yticklabels(channel_names)\n",
    "ax.set_xlabel(\"Channel j\", fontsize=12)\n",
    "ax.set_ylabel(\"Channel i\", fontsize=12)\n",
    "ax.set_title(\"Net TE Matrix (antisymmetric)\", fontsize=12, fontweight=\"bold\")\n",
    "plt.colorbar(im, ax=ax, label=\"Net TE (iâ†’j)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ The TE matrix correctly identifies:\")\n",
    "print(\"   â€¢ Strong Ch1 â†’ Ch2 connection\")\n",
    "print(\"   â€¢ Moderate Ch1 â†’ Ch3 connection\")\n",
    "print(\"   â€¢ Strong Ch4 â†’ Ch5 connection\")\n",
    "print(\"   Note: The matrix is NOT symmetric!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a44f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. TE for Hyperscanning\n",
    "\n",
    "This is **THE** key application for this workshop!\n",
    "\n",
    "### The Central Question\n",
    "> **Who leads the interaction?**\n",
    "\n",
    "### Inter-Brain Transfer Entropy\n",
    "- $TE_{P1 \\to P2}$: Information flow from Participant 1 â†’ Participant 2\n",
    "- $TE_{P2 \\to P1}$: Information flow from Participant 2 â†’ Participant 1\n",
    "- **Net TE**: Reveals the dominant direction\n",
    "\n",
    "### Applications in Social Neuroscience\n",
    "| Scenario | What TE reveals |\n",
    "|----------|-----------------|\n",
    "| Leader-follower dynamics | Who initiates actions |\n",
    "| Teacher-student | Direction of knowledge transfer |\n",
    "| Therapist-patient | Interpersonal influence |\n",
    "| Parent-child | Regulatory influence direction |\n",
    "\n",
    "### Advantages of TE for Hyperscanning\n",
    "- âœ“ **Directed** (unlike PLV, coherence, MI)\n",
    "- âœ“ **Captures nonlinear** influences\n",
    "- âœ“ **Time-resolved** analysis possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 12: Hyperscanning TE simulation\n",
    "\n",
    "def compute_te_hyperscanning(\n",
    "    data_p1: NDArray[np.float64],\n",
    "    data_p2: NDArray[np.float64],\n",
    "    k: int = 1,\n",
    "    l: int = 1,\n",
    "    tau: int = 1,\n",
    "    n_bins: int = 8\n",
    ") -> Dict[str, NDArray[np.float64]]:\n",
    "    \"\"\"\n",
    "    Compute inter-brain TE for hyperscanning.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_p1 : NDArray[np.float64]\n",
    "        Participant 1 data, shape (n_channels, n_samples).\n",
    "    data_p2 : NDArray[np.float64]\n",
    "        Participant 2 data, shape (n_channels, n_samples).\n",
    "    k, l : int\n",
    "        History lengths.\n",
    "    tau : int\n",
    "        Embedding delay.\n",
    "    n_bins : int\n",
    "        Number of bins.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Contains: te_p1_to_p2, te_p2_to_p1, net_te matrices.\n",
    "    \"\"\"\n",
    "    n_ch1 = data_p1.shape[0]\n",
    "    n_ch2 = data_p2.shape[0]\n",
    "    \n",
    "    te_p1_to_p2 = np.zeros((n_ch1, n_ch2))\n",
    "    te_p2_to_p1 = np.zeros((n_ch2, n_ch1))\n",
    "    \n",
    "    for i in range(n_ch1):\n",
    "        for j in range(n_ch2):\n",
    "            te_p1_to_p2[i, j] = compute_transfer_entropy(\n",
    "                data_p1[i], data_p2[j], k, l, tau, n_bins\n",
    "            )\n",
    "            te_p2_to_p1[j, i] = compute_transfer_entropy(\n",
    "                data_p2[j], data_p1[i], k, l, tau, n_bins\n",
    "            )\n",
    "    \n",
    "    # Net TE: average across all pairs\n",
    "    mean_p1_to_p2 = np.mean(te_p1_to_p2)\n",
    "    mean_p2_to_p1 = np.mean(te_p2_to_p1)\n",
    "    net_te = mean_p1_to_p2 - mean_p2_to_p1\n",
    "    \n",
    "    return {\n",
    "        \"te_p1_to_p2\": te_p1_to_p2,\n",
    "        \"te_p2_to_p1\": te_p2_to_p1,\n",
    "        \"mean_p1_to_p2\": mean_p1_to_p2,\n",
    "        \"mean_p2_to_p1\": mean_p2_to_p1,\n",
    "        \"net_te\": net_te,\n",
    "        \"leader\": \"P1\" if net_te > 0 else \"P2\"\n",
    "    }\n",
    "\n",
    "\n",
    "# Simulate hyperscanning scenario: P1 leads, P2 follows\n",
    "n_channels = 3\n",
    "n_samples = 4000\n",
    "channel_names = [\"Fz\", \"Cz\", \"Pz\"]\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# P1 generates independent signals\n",
    "data_p1 = np.random.randn(n_channels, n_samples)\n",
    "for ch in range(n_channels):\n",
    "    for t in range(1, n_samples):\n",
    "        data_p1[ch, t] += 0.7 * data_p1[ch, t-1]\n",
    "\n",
    "# P2 is influenced by P1 with some delay\n",
    "delay = 8\n",
    "coupling = 0.5\n",
    "\n",
    "data_p2 = np.random.randn(n_channels, n_samples)\n",
    "for ch in range(n_channels):\n",
    "    for t in range(1, n_samples):\n",
    "        data_p2[ch, t] += 0.7 * data_p2[ch, t-1]\n",
    "    # Add influence from corresponding P1 channel\n",
    "    for t in range(delay, n_samples):\n",
    "        data_p2[ch, t] += coupling * data_p1[ch, t - delay]\n",
    "\n",
    "# Compute inter-brain TE\n",
    "hyper_result = compute_te_hyperscanning(data_p1, data_p2, k=1, l=1, tau=delay, n_bins=8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Left: P1 â†’ P2\n",
    "ax = axes[0]\n",
    "im = ax.imshow(hyper_result[\"te_p1_to_p2\"], cmap=\"Blues\", aspect=\"equal\")\n",
    "ax.set_xticks(range(n_channels))\n",
    "ax.set_yticks(range(n_channels))\n",
    "ax.set_xticklabels([f\"P2-{ch}\" for ch in channel_names])\n",
    "ax.set_yticklabels([f\"P1-{ch}\" for ch in channel_names])\n",
    "ax.set_title(\"TE: P1 â†’ P2\", fontsize=12, fontweight=\"bold\", color=COLORS[\"signal_1\"])\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Middle: P2 â†’ P1\n",
    "ax = axes[1]\n",
    "im = ax.imshow(hyper_result[\"te_p2_to_p1\"], cmap=\"Reds\", aspect=\"equal\")\n",
    "ax.set_xticks(range(n_channels))\n",
    "ax.set_yticks(range(n_channels))\n",
    "ax.set_xticklabels([f\"P1-{ch}\" for ch in channel_names])\n",
    "ax.set_yticklabels([f\"P2-{ch}\" for ch in channel_names])\n",
    "ax.set_title(\"TE: P2 â†’ P1\", fontsize=12, fontweight=\"bold\", color=COLORS[\"signal_2\"])\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Right: Summary bar chart\n",
    "ax = axes[2]\n",
    "bars = ax.bar([\"P1 â†’ P2\", \"P2 â†’ P1\"], \n",
    "              [hyper_result[\"mean_p1_to_p2\"], hyper_result[\"mean_p2_to_p1\"]],\n",
    "              color=[COLORS[\"signal_1\"], COLORS[\"signal_2\"]], alpha=0.8)\n",
    "ax.set_ylabel(\"Mean TE (bits)\", fontsize=12)\n",
    "ax.set_title(f\"Net TE = {hyper_result['net_te']:.3f}\\nLeader: {hyper_result['leader']}\", \n",
    "             fontsize=12, fontweight=\"bold\")\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ðŸ’¡ Inter-brain TE analysis:\")\n",
    "print(f\"   P1 â†’ P2: {hyper_result['mean_p1_to_p2']:.4f} bits (mean)\")\n",
    "print(f\"   P2 â†’ P1: {hyper_result['mean_p2_to_p1']:.4f} bits (mean)\")\n",
    "print(f\"   Net TE: {hyper_result['net_te']:.4f} â†’ {hyper_result['leader']} leads the interaction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363129d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 14. Limitations and Cautions\n",
    "\n",
    "### âš ï¸ Critical Limitations\n",
    "\n",
    "| Limitation | Description | Mitigation |\n",
    "|------------|-------------|------------|\n",
    "| **Data hungry** | TE needs MORE data than MI | Use shorter histories (k, l = 1) |\n",
    "| **Parameter sensitive** | Results depend on k, l, Ï„, n_bins | Report sensitivity analysis |\n",
    "| **NOT causality** | TE measures *prediction*, not causation | Cannot replace experiments |\n",
    "| **Stationarity** | Assumes stable statistics | Use time-resolved TE |\n",
    "| **Confounds** | Common driver creates apparent TE | Control for shared inputs |\n",
    "\n",
    "### The Confound Problem\n",
    "\n",
    "If a hidden variable **Z** drives both **X** and **Y**:\n",
    "\n",
    "```\n",
    "    Z\n",
    "   / \\\n",
    "  â†“   â†“\n",
    "  X   Y\n",
    "```\n",
    "\n",
    "Then TE will detect Xâ†’Y even if X doesn't actually cause Y!\n",
    "\n",
    "> **TE is NOT causation** â€” it's predictive information flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b02559c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 15. Hands-On Exercises\n",
    "\n",
    "### Exercise 1: Delay Detection\n",
    "Create coupled signals with a known delay (e.g., 15 samples). Use TE scanning over Ï„ to recover the true delay.\n",
    "\n",
    "```python\n",
    "# Your code here\n",
    "true_delay = 15\n",
    "# Generate signals...\n",
    "# Scan Ï„ from 1 to 25...\n",
    "# Find the peak...\n",
    "```\n",
    "\n",
    "### Exercise 2: Bidirectional Coupling Analysis\n",
    "Generate signals with asymmetric bidirectional coupling:\n",
    "- X â†’ Y with strength 0.6\n",
    "- Y â†’ X with strength 0.2\n",
    "\n",
    "Compute Net TE and verify it correctly identifies X as the dominant driver.\n",
    "\n",
    "### Exercise 3: Significance Testing\n",
    "1. Generate independent signals\n",
    "2. Compute TE (will be biased positive)\n",
    "3. Run surrogate test â€” is it significant?\n",
    "4. Compare with coupled signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75449836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise Solutions\n",
    "\n",
    "# Exercise 1: Delay Detection\n",
    "print(\"=\" * 50)\n",
    "print(\"Exercise 1: Delay Detection\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "true_delay_ex = 15\n",
    "x_ex, y_ex = generate_coupled_signals(\n",
    "    n_samples=4000,\n",
    "    coupling_x_to_y=0.5,\n",
    "    delay_samples=true_delay_ex,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "tau_range_ex = np.arange(1, 26)\n",
    "te_scan = [compute_transfer_entropy(x_ex, y_ex, k=1, l=1, tau=t, n_bins=8) \n",
    "           for t in tau_range_ex]\n",
    "\n",
    "detected_delay = tau_range_ex[np.argmax(te_scan)]\n",
    "print(f\"True delay: {true_delay_ex} samples\")\n",
    "print(f\"Detected delay (max TE): {detected_delay} samples\")\n",
    "print(f\"Match: {'âœ“' if detected_delay == true_delay_ex else 'âœ—'}\")\n",
    "\n",
    "# Exercise 2: Asymmetric Bidirectional Coupling\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Exercise 2: Asymmetric Bidirectional Coupling\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "x_bidir_ex, y_bidir_ex = generate_simple_coupled_signals(\n",
    "    n_samples=5000,\n",
    "    coupling_x_to_y=0.6,\n",
    "    coupling_y_to_x=0.2,\n",
    "    delay=5,\n",
    "    seed=456\n",
    ")\n",
    "\n",
    "result_bidir = compute_net_transfer_entropy(x_bidir_ex, y_bidir_ex, k=1, l=1, tau=5, n_bins=8)\n",
    "print(f\"TE Xâ†’Y: {result_bidir['te_x_to_y']:.4f} bits\")\n",
    "print(f\"TE Yâ†’X: {result_bidir['te_y_to_x']:.4f} bits\")\n",
    "print(f\"Net TE: {result_bidir['net_te']:.4f}\")\n",
    "print(f\"Dominant: {'X (correct!)' if result_bidir['net_te'] > 0 else 'Y'}\")\n",
    "\n",
    "# Exercise 3: Significance Testing\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Exercise 3: Significance Testing\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "np.random.seed(789)\n",
    "x_indep_ex = np.random.randn(3000)\n",
    "y_indep_ex = np.random.randn(3000)\n",
    "\n",
    "result_sig = te_significance_test(x_indep_ex, y_indep_ex, k=1, l=1, tau=1, \n",
    "                                   n_bins=8, n_surrogates=100, seed=42)\n",
    "print(f\"Independent signals:\")\n",
    "print(f\"  Observed TE: {result_sig['te_observed']:.4f}\")\n",
    "print(f\"  Null mean:   {result_sig['null_mean']:.4f}\")\n",
    "print(f\"  Effective TE: {result_sig['te_effective']:.4f}\")\n",
    "print(f\"  P-value: {result_sig['p_value']:.4f}\")\n",
    "print(f\"  Significant at Î±=0.05: {'No âœ“' if result_sig['p_value'] > 0.05 else 'Yes âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165d985",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 16. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Transfer Entropy** | Measures *directed* information flow |\n",
    "| **Formula** | $TE_{X \\to Y} = I(Y_t; X_{past} \\| Y_{past})$ |\n",
    "| **Asymmetric** | $TE_{X \\to Y} \\neq TE_{Y \\to X}$ |\n",
    "| **Granger Causality** | Information-theoretic version (nonlinear) |\n",
    "| **Embedding** | Requires k, l (history) and Ï„ (delay) |\n",
    "| **Bias** | Always use surrogate testing! |\n",
    "| **Net TE** | $TE_{X \\to Y} - TE_{Y \\to X}$ indicates dominant direction |\n",
    "\n",
    "### For Hyperscanning\n",
    "\n",
    "Transfer Entropy is particularly valuable because it reveals **who leads the interaction**:\n",
    "- Compute TE in both directions\n",
    "- Net TE > 0 â†’ Participant 1 leads\n",
    "- Net TE < 0 â†’ Participant 2 leads\n",
    "- Time-resolved TE â†’ Track leadership dynamics\n",
    "\n",
    "### Critical Reminder\n",
    "\n",
    "> **TE is NOT causation** â€” it measures predictive information, not true causal influence. Confounds can create spurious TE!\n",
    "\n",
    "---\n",
    "\n",
    "## Discussion Questions\n",
    "\n",
    "1. You find $TE_{P1 \\to P2} = 0.15$ bits and $TE_{P2 \\to P1} = 0.08$ bits during a cooperative task. What does this tell you about the interaction?\n",
    "\n",
    "2. TE at Ï„ = 50ms is higher than at Ï„ = 100ms. What might this indicate about neural communication?\n",
    "\n",
    "3. How would you respond to: \"TE is just fancy correlation â€” you're not proving causation\"?\n",
    "\n",
    "4. Your analysis shows P1â†’P2 dominance in alpha but P2â†’P1 dominance in theta. What might this mean?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connectivity-metrics-tutorials-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
