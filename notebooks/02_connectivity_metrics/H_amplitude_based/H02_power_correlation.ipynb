{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H02: Power Correlation (PowCorr)\n",
    "\n",
    "**Duration**: 45 minutes  \n",
    "**Prerequisites**: H01 (Envelope Correlation), A03 (Power Spectrum)  \n",
    "**Next**: Workshop completion / Advanced topics\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Distinguish power correlation from envelope correlation\n",
    "2. Define power correlation as correlation of squared envelopes / band power\n",
    "3. Implement power correlation computation\n",
    "4. Understand time-windowed vs instantaneous approaches\n",
    "5. Apply power correlation to hyperscanning analysis\n",
    "6. Choose between envelope correlation and power correlation\n",
    "7. Complete the amplitude connectivity toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from typing import Any, Tuple\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Color palette\n",
    "COLORS = {\n",
    "    'signal_1': '#2E86AB',\n",
    "    'signal_2': '#E94F37',\n",
    "    'accent': '#A23B72',\n",
    "    'highlight': '#F18F01',\n",
    "    'warning': '#C73E1D',\n",
    "    'subject_1': '#2E86AB',\n",
    "    'subject_2': '#E94F37',\n",
    "}\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Introduction â€” Power vs Amplitude\n",
    "\n",
    "In H01, we learned about **envelope correlation**, which measures the correlation between amplitude envelopes A(t). Now we explore a closely related metric: **power correlation**.\n",
    "\n",
    "The key distinction:\n",
    "- **Amplitude**: A(t) = |z(t)| where z is the analytic signal\n",
    "- **Power**: P(t) = A(t)Â² = |z(t)|Â²\n",
    "\n",
    "**Why power?** There are several reasons to consider power instead of amplitude:\n",
    "\n",
    "1. **Power is standard in spectral analysis**: When we compute PSDs, we work with power, not amplitude\n",
    "2. **Energy relationship**: Power is more directly related to signal \"energy\"\n",
    "3. **Emphasis on peaks**: Squaring emphasizes larger amplitude fluctuations more than smaller ones\n",
    "\n",
    "**Power correlation** is simply the Pearson correlation between power time series. If amplitudes are correlated, powers will be too (squaring is monotonic), but the values won't be identicalâ€”squaring changes the distribution and emphasizes extremes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions from H01\n",
    "\n",
    "def bandpass_filter(\n",
    "    data: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: tuple[float, float],\n",
    "    order: int = 4\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"Apply bandpass filter to signal.\"\"\"\n",
    "    nyq = fs / 2\n",
    "    low, high = band[0] / nyq, band[1] / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return signal.filtfilt(b, a, data, axis=-1)\n",
    "\n",
    "\n",
    "def extract_envelope(\n",
    "    data: NDArray[np.float64]\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"Extract amplitude envelope using Hilbert transform.\"\"\"\n",
    "    analytic = signal.hilbert(data, axis=-1)\n",
    "    return np.abs(analytic)\n",
    "\n",
    "\n",
    "def extract_phase(\n",
    "    data: NDArray[np.float64]\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"Extract instantaneous phase using Hilbert transform.\"\"\"\n",
    "    analytic = signal.hilbert(data, axis=-1)\n",
    "    return np.angle(analytic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Signal â†’ Amplitude â†’ Power\n",
    "\n",
    "np.random.seed(42)\n",
    "fs = 500.0\n",
    "duration = 4.0\n",
    "t = np.arange(0, duration, 1/fs)\n",
    "\n",
    "# Create amplitude-modulated signal\n",
    "modulation = 1 + 0.6 * np.sin(2 * np.pi * 0.3 * t)\n",
    "carrier = np.sin(2 * np.pi * 10 * t)\n",
    "sig = modulation * carrier + 0.15 * np.random.randn(len(t))\n",
    "\n",
    "# Filter and extract envelope/power\n",
    "sig_filt = bandpass_filter(sig, fs, (8, 12))\n",
    "envelope = extract_envelope(sig_filt)\n",
    "power = envelope ** 2\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 9), sharex=True)\n",
    "\n",
    "# Panel 1: Filtered signal\n",
    "ax1 = axes[0]\n",
    "ax1.plot(t, sig_filt, color=COLORS['signal_1'], linewidth=1, alpha=0.8)\n",
    "ax1.set_ylabel('Signal x(t)', fontsize=11)\n",
    "ax1.set_title('Filtered Signal (8-12 Hz)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Panel 2: Amplitude envelope\n",
    "ax2 = axes[1]\n",
    "ax2.plot(t, sig_filt, color=COLORS['signal_1'], linewidth=0.5, alpha=0.3)\n",
    "ax2.plot(t, envelope, color=COLORS['highlight'], linewidth=2.5, label='Amplitude A(t)')\n",
    "ax2.plot(t, -envelope, color=COLORS['highlight'], linewidth=2.5)\n",
    "ax2.set_ylabel('Amplitude A(t)', fontsize=11)\n",
    "ax2.set_title('Amplitude Envelope', fontsize=12, fontweight='bold')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "# Panel 3: Power\n",
    "ax3 = axes[2]\n",
    "ax3.fill_between(t, 0, power, color=COLORS['accent'], alpha=0.5)\n",
    "ax3.plot(t, power, color=COLORS['accent'], linewidth=2, label='Power P(t) = A(t)Â²')\n",
    "ax3.set_xlabel('Time (s)', fontsize=11)\n",
    "ax3.set_ylabel('Power A(t)Â²', fontsize=11)\n",
    "ax3.set_title('Instantaneous Power (amplitude squared)', fontsize=12, fontweight='bold')\n",
    "ax3.legend(loc='upper right')\n",
    "\n",
    "# Annotate peak emphasis\n",
    "peak_idx = np.argmax(envelope[500:1500]) + 500\n",
    "ax2.annotate('Peak amplitude', xy=(t[peak_idx], envelope[peak_idx]), \n",
    "             xytext=(t[peak_idx] + 0.5, envelope[peak_idx] + 0.3),\n",
    "             arrowprops=dict(arrowstyle='->', color='black'), fontsize=10)\n",
    "ax3.annotate('Peak MORE emphasized\\nin power (squared)', xy=(t[peak_idx], power[peak_idx]), \n",
    "             xytext=(t[peak_idx] + 0.5, power[peak_idx] + 0.5),\n",
    "             arrowprops=dict(arrowstyle='->', color='black'), fontsize=10)\n",
    "\n",
    "plt.suptitle('Signal â†’ Amplitude â†’ Power', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ Power (AÂ²) emphasizes large fluctuations more than amplitude (A)\")\n",
    "print(f\"   Max amplitude: {envelope.max():.2f}\")\n",
    "print(f\"   Max power: {power.max():.2f} = {envelope.max():.2f}Â² = {envelope.max()**2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Power Correlation Definition\n",
    "\n",
    "**Power correlation** is defined as:\n",
    "\n",
    "$$PowCorr = Pearson(P_x, P_y) = Pearson(A_x^2, A_y^2)$$\n",
    "\n",
    "where $P(t) = A(t)^2 = |z(t)|^2$ is the instantaneous power.\n",
    "\n",
    "### Properties:\n",
    "\n",
    "- **Range**: -1 to +1 (like envelope correlation)\n",
    "- **PowCorr = +1**: Powers perfectly positively correlated\n",
    "- **PowCorr = 0**: No linear power relationship\n",
    "- **PowCorr < 0**: Anti-correlated powers (rare)\n",
    "\n",
    "### Relationship to envelope correlation:\n",
    "\n",
    "- Usually highly correlated with CCorr\n",
    "- PowCorr is typically slightly higher (squaring reduces noise relative to signal)\n",
    "- Not identicalâ€”they have different emphases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Scatter of CCorr vs PowCorr for many signal pairs\n",
    "\n",
    "np.random.seed(42)\n",
    "n_pairs = 100\n",
    "n_samples = 5000\n",
    "fs = 500.0\n",
    "band = (8, 12)\n",
    "t = np.arange(n_samples) / fs\n",
    "\n",
    "ccorr_values = []\n",
    "powcorr_values = []\n",
    "\n",
    "for _ in range(n_pairs):\n",
    "    # Random coupling strength\n",
    "    coupling = np.random.uniform(0, 1)\n",
    "    \n",
    "    # Generate signals with varying amplitude coupling\n",
    "    shared_mod = 1 + 0.5 * np.sin(2 * np.pi * 0.3 * t)\n",
    "    indep_mod_x = 1 + 0.5 * np.sin(2 * np.pi * (0.3 + np.random.uniform(-0.1, 0.1)) * t + np.random.uniform(0, 2*np.pi))\n",
    "    indep_mod_y = 1 + 0.5 * np.sin(2 * np.pi * (0.3 + np.random.uniform(-0.1, 0.1)) * t + np.random.uniform(0, 2*np.pi))\n",
    "    \n",
    "    env_x = np.sqrt(coupling) * shared_mod + np.sqrt(1-coupling) * indep_mod_x\n",
    "    env_y = np.sqrt(coupling) * shared_mod + np.sqrt(1-coupling) * indep_mod_y\n",
    "    \n",
    "    x = env_x * np.sin(2 * np.pi * 10 * t + np.random.uniform(0, 2*np.pi)) + 0.2 * np.random.randn(n_samples)\n",
    "    y = env_y * np.sin(2 * np.pi * 10 * t + np.random.uniform(0, 2*np.pi)) + 0.2 * np.random.randn(n_samples)\n",
    "    \n",
    "    # Filter and extract\n",
    "    x_filt = bandpass_filter(x, fs, band)\n",
    "    y_filt = bandpass_filter(y, fs, band)\n",
    "    env_x_meas = extract_envelope(x_filt)\n",
    "    env_y_meas = extract_envelope(y_filt)\n",
    "    pow_x = env_x_meas ** 2\n",
    "    pow_y = env_y_meas ** 2\n",
    "    \n",
    "    # Compute correlations\n",
    "    ccorr = stats.pearsonr(env_x_meas, env_y_meas)[0]\n",
    "    powcorr = stats.pearsonr(pow_x, pow_y)[0]\n",
    "    \n",
    "    ccorr_values.append(ccorr)\n",
    "    powcorr_values.append(powcorr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ax.scatter(ccorr_values, powcorr_values, s=50, alpha=0.6, color=COLORS['signal_1'], edgecolors='white')\n",
    "ax.plot([-0.2, 1], [-0.2, 1], 'k--', linewidth=2, label='y = x (identity)')\n",
    "\n",
    "# Fit line\n",
    "z = np.polyfit(ccorr_values, powcorr_values, 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(-0.2, 1, 100)\n",
    "ax.plot(x_line, p(x_line), color=COLORS['highlight'], linewidth=2, \n",
    "        label=f'Fit: y = {z[0]:.2f}x + {z[1]:.2f}')\n",
    "\n",
    "ax.set_xlabel('Envelope Correlation (CCorr)', fontsize=12)\n",
    "ax.set_ylabel('Power Correlation (PowCorr)', fontsize=12)\n",
    "ax.set_title('Envelope vs Power Correlation: Related but Distinct', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.set_xlim(-0.2, 1)\n",
    "ax.set_ylim(-0.2, 1)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# Correlation\n",
    "r = np.corrcoef(ccorr_values, powcorr_values)[0, 1]\n",
    "ax.text(0.05, 0.95, f'r = {r:.3f}', transform=ax.transAxes, fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Correlation between CCorr and PowCorr: r = {r:.3f}\")\n",
    "print(f\"Mean difference (PowCorr - CCorr): {np.mean(np.array(powcorr_values) - np.array(ccorr_values)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Two Approaches to Power Correlation\n",
    "\n",
    "There are two main approaches to computing power correlation:\n",
    "\n",
    "### Approach 1: Instantaneous Power Correlation\n",
    "- Compute P(t) = A(t)Â² at each time point\n",
    "- Correlate power time series\n",
    "- **Advantage**: High temporal resolution\n",
    "\n",
    "### Approach 2: Windowed Band Power Correlation\n",
    "- Divide signal into epochs/windows\n",
    "- Compute band power for each window\n",
    "- Correlate power values across windows\n",
    "- **Advantage**: More robust estimates, lower variance\n",
    "\n",
    "**When to use which?**\n",
    "- **Instantaneous**: Dynamic connectivity studies, short recordings\n",
    "- **Windowed**: More stable estimates, trial-based designs, longer recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Instantaneous vs windowed power\n",
    "\n",
    "np.random.seed(42)\n",
    "fs = 500.0\n",
    "duration = 10.0\n",
    "t = np.arange(0, duration, 1/fs)\n",
    "n_samples = len(t)\n",
    "\n",
    "# Create signal with power modulation\n",
    "modulation = 1 + 0.6 * np.sin(2 * np.pi * 0.2 * t)\n",
    "sig = modulation * np.sin(2 * np.pi * 10 * t) + 0.2 * np.random.randn(n_samples)\n",
    "\n",
    "# Filter and extract\n",
    "sig_filt = bandpass_filter(sig, fs, (8, 12))\n",
    "envelope = extract_envelope(sig_filt)\n",
    "inst_power = envelope ** 2\n",
    "\n",
    "# Windowed power\n",
    "window_sec = 1.0\n",
    "window_samples = int(window_sec * fs)\n",
    "step = window_samples // 2  # 50% overlap\n",
    "\n",
    "window_centers = []\n",
    "windowed_power = []\n",
    "\n",
    "for start in range(0, n_samples - window_samples + 1, step):\n",
    "    end = start + window_samples\n",
    "    window_centers.append((start + end) / 2 / fs)\n",
    "    windowed_power.append(np.mean(inst_power[start:end]))\n",
    "\n",
    "window_centers = np.array(window_centers)\n",
    "windowed_power = np.array(windowed_power)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Instantaneous power\n",
    "ax1 = axes[0]\n",
    "ax1.plot(t, inst_power, color=COLORS['signal_1'], linewidth=1, alpha=0.8)\n",
    "ax1.fill_between(t, 0, inst_power, color=COLORS['signal_1'], alpha=0.3)\n",
    "ax1.set_ylabel('Power', fontsize=11)\n",
    "ax1.set_title('Instantaneous Power P(t) = A(t)Â²\\n(High temporal resolution, more variable)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "\n",
    "# Windowed power\n",
    "ax2 = axes[1]\n",
    "ax2.plot(t, inst_power, color=COLORS['signal_1'], linewidth=0.5, alpha=0.3, label='Instantaneous')\n",
    "ax2.step(window_centers, windowed_power, where='mid', color=COLORS['signal_2'], \n",
    "         linewidth=2.5, label=f'Windowed ({window_sec}s windows)')\n",
    "ax2.scatter(window_centers, windowed_power, color=COLORS['signal_2'], s=50, zorder=5)\n",
    "ax2.set_xlabel('Time (s)', fontsize=11)\n",
    "ax2.set_ylabel('Power', fontsize=11)\n",
    "ax2.set_title('Windowed Band Power\\n(Lower resolution, more robust)', fontsize=12, fontweight='bold')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.suptitle('Instantaneous vs Windowed Power', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Implementing Power Correlation\n",
    "\n",
    "Let's implement both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_instantaneous_power(\n",
    "    sig: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: tuple[float, float]\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Compute instantaneous power time series.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sig : NDArray[np.float64]\n",
    "        Input signal\n",
    "    fs : float\n",
    "        Sampling frequency in Hz\n",
    "    band : tuple[float, float]\n",
    "        Frequency band (low, high) in Hz\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    NDArray[np.float64]\n",
    "        Instantaneous power P(t) = A(t)Â²\n",
    "    \"\"\"\n",
    "    sig_filt = bandpass_filter(sig, fs, band)\n",
    "    envelope = extract_envelope(sig_filt)\n",
    "    return envelope ** 2\n",
    "\n",
    "\n",
    "def compute_windowed_band_power(\n",
    "    sig: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: tuple[float, float],\n",
    "    window_sec: float = 1.0,\n",
    "    overlap: float = 0.5\n",
    ") -> Tuple[NDArray[np.float64], NDArray[np.float64]]:\n",
    "    \"\"\"\n",
    "    Compute band power in sliding windows.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sig : NDArray[np.float64]\n",
    "        Input signal\n",
    "    fs : float\n",
    "        Sampling frequency in Hz\n",
    "    band : tuple[float, float]\n",
    "        Frequency band (low, high) in Hz\n",
    "    window_sec : float, optional\n",
    "        Window length in seconds (default: 1.0)\n",
    "    overlap : float, optional\n",
    "        Overlap fraction 0-1 (default: 0.5)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[NDArray[np.float64], NDArray[np.float64]]\n",
    "        (time_centers, power_values)\n",
    "    \"\"\"\n",
    "    # First compute instantaneous power\n",
    "    inst_power = compute_instantaneous_power(sig, fs, band)\n",
    "    \n",
    "    window_samples = int(window_sec * fs)\n",
    "    step_samples = int(window_samples * (1 - overlap))\n",
    "    n_samples = len(sig)\n",
    "    \n",
    "    time_centers = []\n",
    "    power_values = []\n",
    "    \n",
    "    for start in range(0, n_samples - window_samples + 1, step_samples):\n",
    "        end = start + window_samples\n",
    "        time_centers.append((start + end) / 2 / fs)\n",
    "        power_values.append(np.mean(inst_power[start:end]))\n",
    "    \n",
    "    return np.array(time_centers), np.array(power_values)\n",
    "\n",
    "\n",
    "def compute_power_correlation(\n",
    "    x: NDArray[np.float64],\n",
    "    y: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: tuple[float, float],\n",
    "    method: str = \"instantaneous\",\n",
    "    window_sec: float = 1.0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute power correlation between two signals.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : NDArray[np.float64]\n",
    "        First signal\n",
    "    y : NDArray[np.float64]\n",
    "        Second signal\n",
    "    fs : float\n",
    "        Sampling frequency in Hz\n",
    "    band : tuple[float, float]\n",
    "        Frequency band (low, high) in Hz\n",
    "    method : str, optional\n",
    "        'instantaneous' or 'windowed' (default: 'instantaneous')\n",
    "    window_sec : float, optional\n",
    "        Window length for windowed method (default: 1.0)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Power correlation in range [-1, 1]\n",
    "    \"\"\"\n",
    "    if method == \"instantaneous\":\n",
    "        pow_x = compute_instantaneous_power(x, fs, band)\n",
    "        pow_y = compute_instantaneous_power(y, fs, band)\n",
    "    elif method == \"windowed\":\n",
    "        _, pow_x = compute_windowed_band_power(x, fs, band, window_sec)\n",
    "        _, pow_y = compute_windowed_band_power(y, fs, band, window_sec)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Use 'instantaneous' or 'windowed'.\")\n",
    "    \n",
    "    # Handle constant signals\n",
    "    if np.std(pow_x) == 0 or np.std(pow_y) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    corr, _ = stats.pearsonr(pow_x, pow_y)\n",
    "    return float(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 4: Computation pipeline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.axis('off')\n",
    "\n",
    "# Helper function for boxes\n",
    "def draw_box(ax, x, y, w, h, text, color, fontsize=9):\n",
    "    rect = plt.Rectangle((x-w/2, y-h/2), w, h, fill=True, \n",
    "                          facecolor=color, edgecolor='black', linewidth=2, alpha=0.8)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x, y, text, ha='center', va='center', fontsize=fontsize, fontweight='bold', wrap=True)\n",
    "\n",
    "def draw_arrow(ax, x1, y1, x2, y2, text=''):\n",
    "    ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
    "                arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "    if text:\n",
    "        mid_x, mid_y = (x1+x2)/2, (y1+y2)/2\n",
    "        ax.text(mid_x + 0.3, mid_y, text, fontsize=8)\n",
    "\n",
    "# Shared start\n",
    "draw_box(ax, 5, 9, 3, 0.8, 'Raw Signals\\nx(t), y(t)', '#E8E8E8', 10)\n",
    "draw_arrow(ax, 5, 8.6, 5, 8)\n",
    "draw_box(ax, 5, 7.5, 3, 0.8, 'Bandpass Filter', COLORS['signal_1'])\n",
    "draw_arrow(ax, 5, 7.1, 5, 6.5)\n",
    "draw_box(ax, 5, 6, 3, 0.8, 'Hilbert Transform\\nâ†’ Analytic signal', COLORS['signal_1'])\n",
    "draw_arrow(ax, 5, 5.6, 5, 5)\n",
    "draw_box(ax, 5, 4.5, 3, 0.8, 'Amplitude Envelope\\nA(t) = |z(t)|', COLORS['signal_1'])\n",
    "draw_arrow(ax, 5, 4.1, 5, 3.5)\n",
    "draw_box(ax, 5, 3, 3, 0.8, 'Square\\nP(t) = A(t)Â²', COLORS['highlight'])\n",
    "\n",
    "# Branch\n",
    "draw_arrow(ax, 5, 2.6, 3, 2)\n",
    "draw_arrow(ax, 5, 2.6, 7, 2)\n",
    "\n",
    "# Instantaneous path\n",
    "draw_box(ax, 3, 1.5, 2.5, 0.8, 'Instantaneous\\nP(t)', COLORS['signal_1'])\n",
    "draw_arrow(ax, 3, 1.1, 3, 0.5)\n",
    "draw_box(ax, 3, 0, 2.5, 0.8, 'Pearson(Px, Py)', COLORS['accent'])\n",
    "\n",
    "# Windowed path\n",
    "draw_box(ax, 7, 1.5, 2.5, 0.8, 'Window Average\\nmean(P)', COLORS['signal_2'])\n",
    "draw_arrow(ax, 7, 1.1, 7, 0.5)\n",
    "draw_box(ax, 7, 0, 2.5, 0.8, 'Pearson(Px, Py)', COLORS['accent'])\n",
    "\n",
    "# Labels\n",
    "ax.text(3, -0.8, 'INSTANTANEOUS', ha='center', fontsize=11, fontweight='bold', color=COLORS['signal_1'])\n",
    "ax.text(7, -0.8, 'WINDOWED', ha='center', fontsize=11, fontweight='bold', color=COLORS['signal_2'])\n",
    "\n",
    "ax.set_title('Power Correlation Computation Methods', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Power Correlation with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_power_correlated_signals(\n",
    "    n_samples: int,\n",
    "    fs: float,\n",
    "    frequency: float,\n",
    "    power_correlation_target: float,\n",
    "    modulation_freq: float = 0.5,\n",
    "    seed: int | None = None\n",
    ") -> Tuple[NDArray[np.float64], NDArray[np.float64]]:\n",
    "    \"\"\"\n",
    "    Generate two signals with specified power correlation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        Number of samples\n",
    "    fs : float\n",
    "        Sampling frequency in Hz\n",
    "    frequency : float\n",
    "        Carrier frequency in Hz\n",
    "    power_correlation_target : float\n",
    "        Desired power correlation (0 to 1)\n",
    "    modulation_freq : float, optional\n",
    "        Modulation frequency in Hz (default: 0.5)\n",
    "    seed : int, optional\n",
    "        Random seed\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[NDArray[np.float64], NDArray[np.float64]]\n",
    "        Two signals with correlated power\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    t = np.arange(n_samples) / fs\n",
    "    \n",
    "    # Shared and independent modulation\n",
    "    shared = 1 + 0.5 * np.sin(2 * np.pi * modulation_freq * t)\n",
    "    indep_x = 1 + 0.5 * np.sin(2 * np.pi * modulation_freq * 1.3 * t + np.random.uniform(0, 2*np.pi))\n",
    "    indep_y = 1 + 0.5 * np.sin(2 * np.pi * modulation_freq * 1.7 * t + np.random.uniform(0, 2*np.pi))\n",
    "    \n",
    "    # Mix based on target\n",
    "    shared_weight = np.sqrt(max(0, power_correlation_target))\n",
    "    indep_weight = np.sqrt(1 - max(0, power_correlation_target))\n",
    "    \n",
    "    env_x = shared_weight * shared + indep_weight * indep_x\n",
    "    env_y = shared_weight * shared + indep_weight * indep_y\n",
    "    \n",
    "    # Ensure positive\n",
    "    env_x = np.maximum(env_x, 0.2)\n",
    "    env_y = np.maximum(env_y, 0.2)\n",
    "    \n",
    "    # Generate signals with independent phases\n",
    "    x = env_x * np.sin(2 * np.pi * frequency * t + np.random.uniform(0, 2*np.pi)) + 0.1 * np.random.randn(n_samples)\n",
    "    y = env_y * np.sin(2 * np.pi * frequency * t + np.random.uniform(0, 2*np.pi)) + 0.1 * np.random.randn(n_samples)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 5: Power correlation example\n",
    "\n",
    "np.random.seed(42)\n",
    "fs = 500.0\n",
    "n_samples = 5000\n",
    "band = (8, 12)\n",
    "\n",
    "x, y = generate_power_correlated_signals(n_samples, fs, 10.0, 0.8, seed=42)\n",
    "t = np.arange(n_samples) / fs\n",
    "\n",
    "# Compute power\n",
    "pow_x = compute_instantaneous_power(x, fs, band)\n",
    "pow_y = compute_instantaneous_power(y, fs, band)\n",
    "powcorr = stats.pearsonr(pow_x, pow_y)[0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Panel 1: Filtered signals\n",
    "ax1 = axes[0, 0]\n",
    "x_filt = bandpass_filter(x, fs, band)\n",
    "y_filt = bandpass_filter(y, fs, band)\n",
    "ax1.plot(t, x_filt, color=COLORS['signal_1'], linewidth=1, alpha=0.8, label='Signal X')\n",
    "ax1.plot(t, y_filt, color=COLORS['signal_2'], linewidth=1, alpha=0.8, label='Signal Y')\n",
    "ax1.set_xlabel('Time (s)', fontsize=11)\n",
    "ax1.set_ylabel('Amplitude', fontsize=11)\n",
    "ax1.set_title('Filtered Signals (8-12 Hz)', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.set_xlim(0, 5)\n",
    "\n",
    "# Panel 2: Power time series\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(t, pow_x, color=COLORS['signal_1'], linewidth=1.5, label='Power X')\n",
    "ax2.plot(t, pow_y, color=COLORS['signal_2'], linewidth=1.5, label='Power Y')\n",
    "ax2.set_xlabel('Time (s)', fontsize=11)\n",
    "ax2.set_ylabel('Power', fontsize=11)\n",
    "ax2.set_title('Instantaneous Power P(t) = A(t)Â²', fontsize=12, fontweight='bold')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "# Panel 3: Power scatter\n",
    "ax3 = axes[1, 0]\n",
    "ax3.scatter(pow_x, pow_y, alpha=0.2, color=COLORS['accent'], s=5)\n",
    "# Fit line\n",
    "z = np.polyfit(pow_x, pow_y, 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(pow_x.min(), pow_x.max(), 100)\n",
    "ax3.plot(x_line, p(x_line), color=COLORS['highlight'], linewidth=2, label=f'r = {powcorr:.3f}')\n",
    "ax3.set_xlabel('Power X', fontsize=11)\n",
    "ax3.set_ylabel('Power Y', fontsize=11)\n",
    "ax3.set_title('Power Correlation', fontsize=12, fontweight='bold')\n",
    "ax3.legend(loc='upper left')\n",
    "\n",
    "# Panel 4: Result\n",
    "ax4 = axes[1, 1]\n",
    "env_x = extract_envelope(x_filt)\n",
    "env_y = extract_envelope(y_filt)\n",
    "ccorr = stats.pearsonr(env_x, env_y)[0]\n",
    "\n",
    "bars = ax4.bar(['CCorr\\n(Envelope)', 'PowCorr\\n(Power)'], [ccorr, powcorr],\n",
    "               color=[COLORS['signal_1'], COLORS['accent']], edgecolor='white', linewidth=2)\n",
    "for bar, val in zip(bars, [ccorr, powcorr]):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "             f'{val:.3f}', ha='center', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Correlation', fontsize=11)\n",
    "ax4.set_title('Comparison: Envelope vs Power Correlation', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylim(0, 1.1)\n",
    "\n",
    "plt.suptitle('Power Correlation Example', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 6: When CCorr and PowCorr diverge\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Scenario: Add low-amplitude noise that affects envelope more than power\n",
    "n_samples = 10000\n",
    "fs = 500.0\n",
    "t = np.arange(n_samples) / fs\n",
    "band = (8, 12)\n",
    "\n",
    "# Clean signals with high coupling\n",
    "shared_mod = 1 + 0.5 * np.sin(2 * np.pi * 0.3 * t)\n",
    "x_clean = shared_mod * np.sin(2 * np.pi * 10 * t)\n",
    "y_clean = shared_mod * np.sin(2 * np.pi * 10 * t + np.pi/4)\n",
    "\n",
    "# Add different noise levels\n",
    "noise_levels = [0.0, 0.3, 0.6, 1.0]\n",
    "ccorrs = []\n",
    "powcorrs = []\n",
    "\n",
    "for noise in noise_levels:\n",
    "    x = x_clean + noise * np.random.randn(n_samples)\n",
    "    y = y_clean + noise * np.random.randn(n_samples)\n",
    "    \n",
    "    x_filt = bandpass_filter(x, fs, band)\n",
    "    y_filt = bandpass_filter(y, fs, band)\n",
    "    \n",
    "    env_x = extract_envelope(x_filt)\n",
    "    env_y = extract_envelope(y_filt)\n",
    "    pow_x = env_x ** 2\n",
    "    pow_y = env_y ** 2\n",
    "    \n",
    "    ccorrs.append(stats.pearsonr(env_x, env_y)[0])\n",
    "    powcorrs.append(stats.pearsonr(pow_x, pow_y)[0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Line plot\n",
    "ax1 = axes[0]\n",
    "ax1.plot(noise_levels, ccorrs, 'o-', color=COLORS['signal_1'], linewidth=2, markersize=10, label='CCorr (Envelope)')\n",
    "ax1.plot(noise_levels, powcorrs, 's-', color=COLORS['accent'], linewidth=2, markersize=10, label='PowCorr (Power)')\n",
    "ax1.set_xlabel('Noise Level (std)', fontsize=12)\n",
    "ax1.set_ylabel('Correlation', fontsize=12)\n",
    "ax1.set_title('Effect of Noise on Envelope vs Power Correlation', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='lower left', fontsize=11)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Difference\n",
    "ax2 = axes[1]\n",
    "diff = np.array(powcorrs) - np.array(ccorrs)\n",
    "colors_bar = [COLORS['highlight'] if d > 0 else COLORS['signal_2'] for d in diff]\n",
    "bars = ax2.bar([f'{n}' for n in noise_levels], diff, color=colors_bar, edgecolor='white', linewidth=2)\n",
    "ax2.axhline(0, color='black', linestyle='-', linewidth=1)\n",
    "for bar, val in zip(bars, diff):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005 * np.sign(val),\n",
    "             f'{val:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "ax2.set_xlabel('Noise Level', fontsize=12)\n",
    "ax2.set_ylabel('PowCorr - CCorr', fontsize=12)\n",
    "ax2.set_title('Difference: Power correlation often slightly higher', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('When Envelope and Power Correlation Diverge', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ Power correlation tends to be slightly more robust to noise\")\n",
    "print(\"   because squaring reduces relative noise contribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Volume Conduction and Orthogonalization\n",
    "\n",
    "Just like envelope correlation, **power correlation is inflated by volume conduction**. The same solution applies: **orthogonalization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_orthogonalized_power_correlation(\n",
    "    x: NDArray[np.float64],\n",
    "    y: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: tuple[float, float],\n",
    "    symmetric: bool = True\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute power correlation with orthogonalization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : NDArray[np.float64]\n",
    "        First signal\n",
    "    y : NDArray[np.float64]\n",
    "        Second signal\n",
    "    fs : float\n",
    "        Sampling frequency in Hz\n",
    "    band : tuple[float, float]\n",
    "        Frequency band (low, high) in Hz\n",
    "    symmetric : bool, optional\n",
    "        If True, average both directions (default: True)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Orthogonalized power correlation in range [-1, 1]\n",
    "    \"\"\"\n",
    "    # Bandpass filter\n",
    "    x_filt = bandpass_filter(x, fs, band)\n",
    "    y_filt = bandpass_filter(y, fs, band)\n",
    "    \n",
    "    # Analytic signals\n",
    "    z_x = signal.hilbert(x_filt)\n",
    "    z_y = signal.hilbert(y_filt)\n",
    "    \n",
    "    # Phases and envelopes\n",
    "    phase_x = np.angle(z_x)\n",
    "    phase_y = np.angle(z_y)\n",
    "    env_x = np.abs(z_x)\n",
    "    \n",
    "    # Orthogonalize y with respect to x\n",
    "    y_orth = np.imag(z_y * np.exp(-1j * phase_x))\n",
    "    env_y_orth = np.abs(y_orth)\n",
    "    \n",
    "    # Power\n",
    "    pow_x = env_x ** 2\n",
    "    pow_y_orth = env_y_orth ** 2\n",
    "    \n",
    "    # Correlation\n",
    "    if np.std(pow_x) == 0 or np.std(pow_y_orth) == 0:\n",
    "        corr1 = 0.0\n",
    "    else:\n",
    "        corr1 = stats.pearsonr(pow_x, pow_y_orth)[0]\n",
    "    \n",
    "    if symmetric:\n",
    "        # Also compute in other direction\n",
    "        env_y = np.abs(z_y)\n",
    "        x_orth = np.imag(z_x * np.exp(-1j * phase_y))\n",
    "        env_x_orth = np.abs(x_orth)\n",
    "        \n",
    "        pow_y = env_y ** 2\n",
    "        pow_x_orth = env_x_orth ** 2\n",
    "        \n",
    "        if np.std(pow_y) == 0 or np.std(pow_x_orth) == 0:\n",
    "            corr2 = 0.0\n",
    "        else:\n",
    "            corr2 = stats.pearsonr(pow_y, pow_x_orth)[0]\n",
    "        \n",
    "        return float((corr1 + corr2) / 2)\n",
    "    \n",
    "    return float(corr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 7: Volume conduction test\n",
    "\n",
    "np.random.seed(42)\n",
    "fs = 500.0\n",
    "n_samples = 10000\n",
    "t = np.arange(n_samples) / fs\n",
    "band = (8, 12)\n",
    "\n",
    "# Volume conduction scenario\n",
    "source = (1 + 0.5 * np.sin(2 * np.pi * 0.3 * t)) * np.sin(2 * np.pi * 10 * t)\n",
    "x_vc = source + 0.1 * np.random.randn(n_samples)\n",
    "y_vc = 0.9 * source + 0.1 * np.random.randn(n_samples)\n",
    "\n",
    "# True connection scenario\n",
    "mod = 1 + 0.5 * np.sin(2 * np.pi * 0.3 * t)\n",
    "x_true = mod * np.sin(2 * np.pi * 10 * t) + 0.2 * np.random.randn(n_samples)\n",
    "y_true = mod * np.sin(2 * np.pi * 10 * t + np.pi/4) + 0.2 * np.random.randn(n_samples)\n",
    "\n",
    "# Compute correlations\n",
    "powcorr_vc_std = compute_power_correlation(x_vc, y_vc, fs, band)\n",
    "powcorr_vc_orth = compute_orthogonalized_power_correlation(x_vc, y_vc, fs, band)\n",
    "powcorr_true_std = compute_power_correlation(x_true, y_true, fs, band)\n",
    "powcorr_true_orth = compute_orthogonalized_power_correlation(x_true, y_true, fs, band)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x_pos = np.array([0, 1, 3, 4])\n",
    "values = [powcorr_vc_std, powcorr_vc_orth, powcorr_true_std, powcorr_true_orth]\n",
    "colors_bar = [COLORS['warning'], COLORS['signal_1'], COLORS['warning'], COLORS['signal_1']]\n",
    "\n",
    "bars = ax.bar(x_pos, values, color=colors_bar, edgecolor='white', linewidth=2, width=0.8)\n",
    "\n",
    "for bar, val in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.03,\n",
    "            f'{val:.3f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xticks([0.5, 3.5])\n",
    "ax.set_xticklabels(['Volume Conduction\\n(Should be LOW)', 'True Connection\\n(Should remain HIGH)'], fontsize=11)\n",
    "ax.set_ylabel('Power Correlation', fontsize=12)\n",
    "ax.set_title('Orthogonalized Power Correlation is Robust to Volume Conduction', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=COLORS['warning'], label='Standard'),\n",
    "                   Patch(facecolor=COLORS['signal_1'], label='Orthogonalized')]\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Volume Conduction:\")\n",
    "print(f\"  Standard: {powcorr_vc_std:.3f} â†’ Orthogonalized: {powcorr_vc_orth:.3f}\")\n",
    "print(f\"\\nTrue Connection:\")\n",
    "print(f\"  Standard: {powcorr_true_std:.3f} â†’ Orthogonalized: {powcorr_true_orth:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Power Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_power_correlation_matrix(\n",
    "    data: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: tuple[float, float],\n",
    "    orthogonalize: bool = True\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Compute power correlation matrix for all channel pairs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : NDArray[np.float64]\n",
    "        EEG data with shape (n_channels, n_samples)\n",
    "    fs : float\n",
    "        Sampling frequency in Hz\n",
    "    band : tuple[float, float]\n",
    "        Frequency band (low, high) in Hz\n",
    "    orthogonalize : bool, optional\n",
    "        Whether to use orthogonalization (default: True)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    NDArray[np.float64]\n",
    "        Power correlation matrix\n",
    "    \"\"\"\n",
    "    n_channels = data.shape[0]\n",
    "    \n",
    "    # Filter and get analytic signals\n",
    "    data_filt = bandpass_filter(data, fs, band)\n",
    "    z_data = signal.hilbert(data_filt, axis=-1)\n",
    "    phases = np.angle(z_data)\n",
    "    envelopes = np.abs(z_data)\n",
    "    powers = envelopes ** 2\n",
    "    \n",
    "    # Initialize matrix\n",
    "    powcorr_matrix = np.eye(n_channels)\n",
    "    \n",
    "    for i in range(n_channels):\n",
    "        for j in range(i + 1, n_channels):\n",
    "            if orthogonalize:\n",
    "                # Orthogonalize j w.r.t. i\n",
    "                j_orth = np.imag(z_data[j] * np.exp(-1j * phases[i]))\n",
    "                pow_j_orth = np.abs(j_orth) ** 2\n",
    "                corr1 = stats.pearsonr(powers[i], pow_j_orth)[0] if np.std(pow_j_orth) > 0 else 0\n",
    "                \n",
    "                # Orthogonalize i w.r.t. j\n",
    "                i_orth = np.imag(z_data[i] * np.exp(-1j * phases[j]))\n",
    "                pow_i_orth = np.abs(i_orth) ** 2\n",
    "                corr2 = stats.pearsonr(powers[j], pow_i_orth)[0] if np.std(pow_i_orth) > 0 else 0\n",
    "                \n",
    "                powcorr = (corr1 + corr2) / 2\n",
    "            else:\n",
    "                powcorr = stats.pearsonr(powers[i], powers[j])[0]\n",
    "            \n",
    "            powcorr_matrix[i, j] = powcorr\n",
    "            powcorr_matrix[j, i] = powcorr\n",
    "    \n",
    "    return powcorr_matrix\n",
    "\n",
    "\n",
    "def compute_envelope_correlation_matrix(\n",
    "    data: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: tuple[float, float],\n",
    "    orthogonalize: bool = True\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"Compute envelope correlation matrix (from H01).\"\"\"\n",
    "    n_channels = data.shape[0]\n",
    "    data_filt = bandpass_filter(data, fs, band)\n",
    "    z_data = signal.hilbert(data_filt, axis=-1)\n",
    "    phases = np.angle(z_data)\n",
    "    envelopes = np.abs(z_data)\n",
    "    \n",
    "    ccorr_matrix = np.eye(n_channels)\n",
    "    \n",
    "    for i in range(n_channels):\n",
    "        for j in range(i + 1, n_channels):\n",
    "            if orthogonalize:\n",
    "                j_orth = np.abs(np.imag(z_data[j] * np.exp(-1j * phases[i])))\n",
    "                i_orth = np.abs(np.imag(z_data[i] * np.exp(-1j * phases[j])))\n",
    "                c1 = stats.pearsonr(envelopes[i], j_orth)[0] if np.std(j_orth) > 0 else 0\n",
    "                c2 = stats.pearsonr(envelopes[j], i_orth)[0] if np.std(i_orth) > 0 else 0\n",
    "                ccorr = (c1 + c2) / 2\n",
    "            else:\n",
    "                ccorr = stats.pearsonr(envelopes[i], envelopes[j])[0]\n",
    "            \n",
    "            ccorr_matrix[i, j] = ccorr\n",
    "            ccorr_matrix[j, i] = ccorr\n",
    "    \n",
    "    return ccorr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multi-channel data\n",
    "np.random.seed(42)\n",
    "n_channels = 8\n",
    "n_samples = 5000\n",
    "fs = 500.0\n",
    "t = np.arange(n_samples) / fs\n",
    "\n",
    "data = np.zeros((n_channels, n_samples))\n",
    "\n",
    "# Cluster 1 (ch 0-2): shared modulation\n",
    "shared_mod_1 = 1 + 0.5 * np.sin(2 * np.pi * 0.3 * t)\n",
    "for i in range(3):\n",
    "    data[i] = shared_mod_1 * np.sin(2 * np.pi * 10 * t + np.random.uniform(0, 2*np.pi)) + 0.2 * np.random.randn(n_samples)\n",
    "\n",
    "# Cluster 2 (ch 3-5): different shared modulation\n",
    "shared_mod_2 = 1 + 0.5 * np.sin(2 * np.pi * 0.4 * t + 1.5)\n",
    "for i in range(3, 6):\n",
    "    data[i] = shared_mod_2 * np.sin(2 * np.pi * 10 * t + np.random.uniform(0, 2*np.pi)) + 0.2 * np.random.randn(n_samples)\n",
    "\n",
    "# Independent (ch 6-7)\n",
    "for i in range(6, 8):\n",
    "    indep_mod = 1 + 0.5 * np.sin(2 * np.pi * (0.3 + 0.1*i) * t + np.random.uniform(0, 2*np.pi))\n",
    "    data[i] = indep_mod * np.sin(2 * np.pi * 10 * t + np.random.uniform(0, 2*np.pi)) + 0.3 * np.random.randn(n_samples)\n",
    "\n",
    "# Compute matrices\n",
    "ccorr_mat = compute_envelope_correlation_matrix(data, fs, (8, 12), orthogonalize=True)\n",
    "powcorr_mat = compute_power_correlation_matrix(data, fs, (8, 12), orthogonalize=True)\n",
    "diff_mat = powcorr_mat - ccorr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 8: Three matrices comparison\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4.5))\n",
    "\n",
    "# CCorr\n",
    "ax1 = axes[0]\n",
    "im1 = ax1.imshow(ccorr_mat, cmap='RdBu_r', vmin=-1, vmax=1, aspect='equal')\n",
    "ax1.set_title('Envelope Correlation (CCorr)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Channel', fontsize=11)\n",
    "ax1.set_ylabel('Channel', fontsize=11)\n",
    "ax1.set_xticks(range(n_channels))\n",
    "ax1.set_yticks(range(n_channels))\n",
    "for pos in [2.5, 5.5]:\n",
    "    ax1.axhline(pos, color='white', linewidth=1)\n",
    "    ax1.axvline(pos, color='white', linewidth=1)\n",
    "plt.colorbar(im1, ax=ax1, shrink=0.8)\n",
    "\n",
    "# PowCorr\n",
    "ax2 = axes[1]\n",
    "im2 = ax2.imshow(powcorr_mat, cmap='RdBu_r', vmin=-1, vmax=1, aspect='equal')\n",
    "ax2.set_title('Power Correlation (PowCorr)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Channel', fontsize=11)\n",
    "ax2.set_ylabel('Channel', fontsize=11)\n",
    "ax2.set_xticks(range(n_channels))\n",
    "ax2.set_yticks(range(n_channels))\n",
    "for pos in [2.5, 5.5]:\n",
    "    ax2.axhline(pos, color='white', linewidth=1)\n",
    "    ax2.axvline(pos, color='white', linewidth=1)\n",
    "plt.colorbar(im2, ax=ax2, shrink=0.8)\n",
    "\n",
    "# Difference\n",
    "ax3 = axes[2]\n",
    "max_diff = np.max(np.abs(diff_mat))\n",
    "im3 = ax3.imshow(diff_mat, cmap='RdBu_r', vmin=-max_diff, vmax=max_diff, aspect='equal')\n",
    "ax3.set_title('Difference (PowCorr - CCorr)', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Channel', fontsize=11)\n",
    "ax3.set_ylabel('Channel', fontsize=11)\n",
    "ax3.set_xticks(range(n_channels))\n",
    "ax3.set_yticks(range(n_channels))\n",
    "for pos in [2.5, 5.5]:\n",
    "    ax3.axhline(pos, color='black', linewidth=1, alpha=0.3)\n",
    "    ax3.axvline(pos, color='black', linewidth=1, alpha=0.3)\n",
    "plt.colorbar(im3, ax=ax3, shrink=0.8)\n",
    "\n",
    "plt.suptitle('Comparing Envelope and Power Correlation Matrices (Orthogonalized)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean absolute difference: {np.mean(np.abs(diff_mat[np.triu_indices(n_channels, k=1)])):.4f}\")\n",
    "print(f\"Max absolute difference: {np.max(np.abs(diff_mat[np.triu_indices(n_channels, k=1)])):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Power Correlation for Hyperscanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_power_correlation_hyperscanning(\n",
    "    data_p1: NDArray[np.float64],\n",
    "    data_p2: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: tuple[float, float],\n",
    "    orthogonalize_within: bool = True\n",
    ") -> dict[str, NDArray[np.float64]]:\n",
    "    \"\"\"\n",
    "    Compute power correlation matrices for hyperscanning.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_p1 : NDArray[np.float64]\n",
    "        Data from participant 1, shape (n_channels, n_samples)\n",
    "    data_p2 : NDArray[np.float64]\n",
    "        Data from participant 2\n",
    "    fs : float\n",
    "        Sampling frequency\n",
    "    band : tuple[float, float]\n",
    "        Frequency band\n",
    "    orthogonalize_within : bool, optional\n",
    "        Orthogonalize within-brain (default: True)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, NDArray[np.float64]]\n",
    "        within_p1, within_p2, between, full matrices\n",
    "    \"\"\"\n",
    "    n_ch1 = data_p1.shape[0]\n",
    "    n_ch2 = data_p2.shape[0]\n",
    "    \n",
    "    # Filter and analytic\n",
    "    data_p1_filt = bandpass_filter(data_p1, fs, band)\n",
    "    data_p2_filt = bandpass_filter(data_p2, fs, band)\n",
    "    \n",
    "    z_p1 = signal.hilbert(data_p1_filt, axis=-1)\n",
    "    z_p2 = signal.hilbert(data_p2_filt, axis=-1)\n",
    "    \n",
    "    phases_p1 = np.angle(z_p1)\n",
    "    phases_p2 = np.angle(z_p2)\n",
    "    powers_p1 = np.abs(z_p1) ** 2\n",
    "    powers_p2 = np.abs(z_p2) ** 2\n",
    "    \n",
    "    # Within P1\n",
    "    within_p1 = np.eye(n_ch1)\n",
    "    for i in range(n_ch1):\n",
    "        for j in range(i + 1, n_ch1):\n",
    "            if orthogonalize_within:\n",
    "                j_orth = np.abs(np.imag(z_p1[j] * np.exp(-1j * phases_p1[i]))) ** 2\n",
    "                i_orth = np.abs(np.imag(z_p1[i] * np.exp(-1j * phases_p1[j]))) ** 2\n",
    "                c1 = stats.pearsonr(powers_p1[i], j_orth)[0] if np.std(j_orth) > 0 else 0\n",
    "                c2 = stats.pearsonr(powers_p1[j], i_orth)[0] if np.std(i_orth) > 0 else 0\n",
    "                pc = (c1 + c2) / 2\n",
    "            else:\n",
    "                pc = stats.pearsonr(powers_p1[i], powers_p1[j])[0]\n",
    "            within_p1[i, j] = pc\n",
    "            within_p1[j, i] = pc\n",
    "    \n",
    "    # Within P2\n",
    "    within_p2 = np.eye(n_ch2)\n",
    "    for i in range(n_ch2):\n",
    "        for j in range(i + 1, n_ch2):\n",
    "            if orthogonalize_within:\n",
    "                j_orth = np.abs(np.imag(z_p2[j] * np.exp(-1j * phases_p2[i]))) ** 2\n",
    "                i_orth = np.abs(np.imag(z_p2[i] * np.exp(-1j * phases_p2[j]))) ** 2\n",
    "                c1 = stats.pearsonr(powers_p2[i], j_orth)[0] if np.std(j_orth) > 0 else 0\n",
    "                c2 = stats.pearsonr(powers_p2[j], i_orth)[0] if np.std(i_orth) > 0 else 0\n",
    "                pc = (c1 + c2) / 2\n",
    "            else:\n",
    "                pc = stats.pearsonr(powers_p2[i], powers_p2[j])[0]\n",
    "            within_p2[i, j] = pc\n",
    "            within_p2[j, i] = pc\n",
    "    \n",
    "    # Between (no orthogonalization needed)\n",
    "    between = np.zeros((n_ch1, n_ch2))\n",
    "    for i in range(n_ch1):\n",
    "        for j in range(n_ch2):\n",
    "            between[i, j] = stats.pearsonr(powers_p1[i], powers_p2[j])[0]\n",
    "    \n",
    "    # Full matrix\n",
    "    n_total = n_ch1 + n_ch2\n",
    "    full = np.zeros((n_total, n_total))\n",
    "    full[:n_ch1, :n_ch1] = within_p1\n",
    "    full[n_ch1:, n_ch1:] = within_p2\n",
    "    full[:n_ch1, n_ch1:] = between\n",
    "    full[n_ch1:, :n_ch1] = between.T\n",
    "    \n",
    "    return {\n",
    "        'within_p1': within_p1,\n",
    "        'within_p2': within_p2,\n",
    "        'between': between,\n",
    "        'full': full\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hyperscanning data\n",
    "np.random.seed(42)\n",
    "n_channels_per = 4\n",
    "n_samples = 5000\n",
    "fs = 500.0\n",
    "t = np.arange(n_samples) / fs\n",
    "\n",
    "# Shared between-brain modulation\n",
    "shared_mod = 1 + 0.3 * np.sin(2 * np.pi * 0.2 * t)\n",
    "\n",
    "# P1\n",
    "p1_mod = 1 + 0.4 * np.sin(2 * np.pi * 0.3 * t)\n",
    "data_p1 = np.zeros((n_channels_per, n_samples))\n",
    "for i in range(n_channels_per):\n",
    "    combined = 0.5 * p1_mod + 0.3 * shared_mod + 0.2\n",
    "    data_p1[i] = combined * np.sin(2 * np.pi * 10 * t + np.random.uniform(0, 2*np.pi)) + 0.15 * np.random.randn(n_samples)\n",
    "\n",
    "# P2\n",
    "p2_mod = 1 + 0.4 * np.sin(2 * np.pi * 0.35 * t + 1.0)\n",
    "data_p2 = np.zeros((n_channels_per, n_samples))\n",
    "for i in range(n_channels_per):\n",
    "    combined = 0.5 * p2_mod + 0.3 * shared_mod + 0.2\n",
    "    data_p2[i] = combined * np.sin(2 * np.pi * 10 * t + np.random.uniform(0, 2*np.pi)) + 0.15 * np.random.randn(n_samples)\n",
    "\n",
    "# Compute\n",
    "hyper_powcorr = compute_power_correlation_hyperscanning(data_p1, data_p2, fs, (8, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 9: Hyperscanning power correlation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "im = ax.imshow(hyper_powcorr['full'], cmap='RdBu_r', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "# Block separators\n",
    "ax.axhline(n_channels_per - 0.5, color='black', linewidth=2)\n",
    "ax.axvline(n_channels_per - 0.5, color='black', linewidth=2)\n",
    "\n",
    "# Labels\n",
    "n_total = 2 * n_channels_per\n",
    "labels = [f'P1-{i}' for i in range(n_channels_per)] + [f'P2-{i}' for i in range(n_channels_per)]\n",
    "ax.set_xticks(range(n_total))\n",
    "ax.set_yticks(range(n_total))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "# Block annotations\n",
    "ax.text(1.5, 1.5, 'Within\\nP1', ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "ax.text(5.5, 5.5, 'Within\\nP2', ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "ax.text(5.5, 1.5, 'Between', ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_title('Inter-Brain Power Correlation', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax, shrink=0.8, label='PowCorr')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary stats\n",
    "mean_within_p1 = np.mean(hyper_powcorr['within_p1'][np.triu_indices(n_channels_per, k=1)])\n",
    "mean_within_p2 = np.mean(hyper_powcorr['within_p2'][np.triu_indices(n_channels_per, k=1)])\n",
    "mean_between = np.mean(hyper_powcorr['between'])\n",
    "\n",
    "print(f\"Mean power correlation:\")\n",
    "print(f\"  Within P1: {mean_within_p1:.3f}\")\n",
    "print(f\"  Within P2: {mean_within_p2:.3f}\")\n",
    "print(f\"  Between:   {mean_between:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Choosing Between Amplitude Metrics\n",
    "\n",
    "### Envelope Correlation (CCorr)\n",
    "- Most commonly used in literature\n",
    "- Linear in amplitude\n",
    "- Easier to compare with existing studies\n",
    "\n",
    "### Power Correlation (PowCorr)\n",
    "- Emphasizes larger fluctuations (squared)\n",
    "- May be more robust to low-amplitude noise\n",
    "- Matches spectral analysis (which uses power)\n",
    "\n",
    "**Recommendation**: CCorr is the standard choice. PowCorr is an alternative when robustness to noise is important. Always report which metric you used!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 10: Complete Connectivity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_amplitude_metrics(\n",
    "    x: NDArray[np.float64],\n",
    "    y: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: tuple[float, float]\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute all amplitude connectivity metrics.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, float]\n",
    "        ccorr, ccorr_orth, powcorr, powcorr_orth\n",
    "    \"\"\"\n",
    "    # Filter and extract\n",
    "    x_filt = bandpass_filter(x, fs, band)\n",
    "    y_filt = bandpass_filter(y, fs, band)\n",
    "    \n",
    "    env_x = extract_envelope(x_filt)\n",
    "    env_y = extract_envelope(y_filt)\n",
    "    pow_x = env_x ** 2\n",
    "    pow_y = env_y ** 2\n",
    "    \n",
    "    ccorr = stats.pearsonr(env_x, env_y)[0]\n",
    "    powcorr = stats.pearsonr(pow_x, pow_y)[0]\n",
    "    \n",
    "    # Orthogonalized (simplified)\n",
    "    z_x = signal.hilbert(x_filt)\n",
    "    z_y = signal.hilbert(y_filt)\n",
    "    phase_x = np.angle(z_x)\n",
    "    phase_y = np.angle(z_y)\n",
    "    \n",
    "    y_orth = np.abs(np.imag(z_y * np.exp(-1j * phase_x)))\n",
    "    x_orth = np.abs(np.imag(z_x * np.exp(-1j * phase_y)))\n",
    "    \n",
    "    ccorr_orth = (stats.pearsonr(env_x, y_orth)[0] + stats.pearsonr(env_y, x_orth)[0]) / 2\n",
    "    powcorr_orth = (stats.pearsonr(pow_x, y_orth**2)[0] + stats.pearsonr(pow_y, x_orth**2)[0]) / 2\n",
    "    \n",
    "    return {\n",
    "        'ccorr': ccorr,\n",
    "        'ccorr_orth': ccorr_orth,\n",
    "        'powcorr': powcorr,\n",
    "        'powcorr_orth': powcorr_orth\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_all_connectivity_metrics(\n",
    "    x: NDArray[np.float64],\n",
    "    y: NDArray[np.float64],\n",
    "    fs: float,\n",
    "    band: tuple[float, float]\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute complete connectivity profile (phase + amplitude).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, float]\n",
    "        All phase and amplitude metrics\n",
    "    \"\"\"\n",
    "    # Filter\n",
    "    x_filt = bandpass_filter(x, fs, band)\n",
    "    y_filt = bandpass_filter(y, fs, band)\n",
    "    \n",
    "    # Analytic signals\n",
    "    z_x = signal.hilbert(x_filt)\n",
    "    z_y = signal.hilbert(y_filt)\n",
    "    \n",
    "    phase_x = np.angle(z_x)\n",
    "    phase_y = np.angle(z_y)\n",
    "    env_x = np.abs(z_x)\n",
    "    env_y = np.abs(z_y)\n",
    "    \n",
    "    phase_diff = phase_x - phase_y\n",
    "    \n",
    "    # Phase metrics\n",
    "    plv = float(np.abs(np.mean(np.exp(1j * phase_diff))))\n",
    "    \n",
    "    signs = np.sign(np.sin(phase_diff))\n",
    "    pli = float(np.abs(np.mean(signs)))\n",
    "    \n",
    "    sin_diff = np.sin(phase_diff)\n",
    "    wpli = float(np.abs(np.sum(sin_diff)) / np.sum(np.abs(sin_diff))) if np.sum(np.abs(sin_diff)) > 0 else 0\n",
    "    \n",
    "    # Amplitude metrics\n",
    "    pow_x = env_x ** 2\n",
    "    pow_y = env_y ** 2\n",
    "    \n",
    "    ccorr = stats.pearsonr(env_x, env_y)[0]\n",
    "    powcorr = stats.pearsonr(pow_x, pow_y)[0]\n",
    "    \n",
    "    # Orthogonalized\n",
    "    y_orth = np.abs(np.imag(z_y * np.exp(-1j * phase_x)))\n",
    "    x_orth = np.abs(np.imag(z_x * np.exp(-1j * phase_y)))\n",
    "    \n",
    "    ccorr_orth = (stats.pearsonr(env_x, y_orth)[0] + stats.pearsonr(env_y, x_orth)[0]) / 2\n",
    "    powcorr_orth = (stats.pearsonr(pow_x, y_orth**2)[0] + stats.pearsonr(pow_y, x_orth**2)[0]) / 2\n",
    "    \n",
    "    return {\n",
    "        'plv': plv,\n",
    "        'pli': pli,\n",
    "        'wpli': wpli,\n",
    "        'ccorr': ccorr,\n",
    "        'ccorr_orth': ccorr_orth,\n",
    "        'powcorr': powcorr,\n",
    "        'powcorr_orth': powcorr_orth\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 11: Complete connectivity profile\n",
    "\n",
    "np.random.seed(42)\n",
    "fs = 500.0\n",
    "n_samples = 10000\n",
    "t = np.arange(n_samples) / fs\n",
    "band = (8, 12)\n",
    "\n",
    "# Create signals with both phase and amplitude coupling\n",
    "shared_mod = 1 + 0.5 * np.sin(2 * np.pi * 0.3 * t)\n",
    "x = shared_mod * np.sin(2 * np.pi * 10 * t) + 0.2 * np.random.randn(n_samples)\n",
    "y = shared_mod * np.sin(2 * np.pi * 10 * t + np.pi/6) + 0.2 * np.random.randn(n_samples)\n",
    "\n",
    "# Compute all metrics\n",
    "all_metrics = compute_all_connectivity_metrics(x, y, fs, band)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Group metrics\n",
    "phase_names = ['PLV', 'PLI', 'wPLI']\n",
    "phase_values = [all_metrics['plv'], all_metrics['pli'], all_metrics['wpli']]\n",
    "\n",
    "amp_names = ['CCorr', 'CCorr-orth', 'PowCorr', 'PowCorr-orth']\n",
    "amp_values = [all_metrics['ccorr'], all_metrics['ccorr_orth'], \n",
    "              all_metrics['powcorr'], all_metrics['powcorr_orth']]\n",
    "\n",
    "all_names = phase_names + [''] + amp_names  # Gap between groups\n",
    "all_values = phase_values + [0] + amp_values\n",
    "colors = [COLORS['signal_1']]*3 + ['white'] + [COLORS['accent']]*4\n",
    "\n",
    "x_pos = np.arange(len(all_names))\n",
    "bars = ax.bar(x_pos, all_values, color=colors, edgecolor=['black']*3 + ['white'] + ['black']*4, linewidth=2)\n",
    "\n",
    "# Labels\n",
    "for i, (bar, val) in enumerate(zip(bars, all_values)):\n",
    "    if val > 0:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                f'{val:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(all_names, fontsize=10)\n",
    "ax.set_ylabel('Value', fontsize=12)\n",
    "ax.set_title('Complete Connectivity Profile\\n(Phase + Amplitude Metrics)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Group labels\n",
    "ax.text(1, -0.15, 'PHASE', ha='center', fontsize=11, fontweight='bold', color=COLORS['signal_1'],\n",
    "        transform=ax.get_xaxis_transform())\n",
    "ax.text(5.5, -0.15, 'AMPLITUDE', ha='center', fontsize=11, fontweight='bold', color=COLORS['accent'],\n",
    "        transform=ax.get_xaxis_transform())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nComplete Connectivity Profile:\")\n",
    "print(\"=\"*40)\n",
    "print(\"PHASE METRICS:\")\n",
    "for name in ['plv', 'pli', 'wpli']:\n",
    "    print(f\"  {name.upper()}: {all_metrics[name]:.3f}\")\n",
    "print(\"\\nAMPLITUDE METRICS:\")\n",
    "for name in ['ccorr', 'ccorr_orth', 'powcorr', 'powcorr_orth']:\n",
    "    print(f\"  {name}: {all_metrics[name]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 12: Correlation matrix of metrics across many signal pairs\n",
    "\n",
    "np.random.seed(42)\n",
    "n_pairs = 100\n",
    "\n",
    "metric_names = ['PLV', 'PLI', 'wPLI', 'CCorr', 'CCorr-orth', 'PowCorr', 'PowCorr-orth']\n",
    "all_results = {name: [] for name in metric_names}\n",
    "\n",
    "for _ in range(n_pairs):\n",
    "    # Random coupling\n",
    "    phase_coupling = np.random.uniform(0, 1)\n",
    "    amp_coupling = np.random.uniform(0, 1)\n",
    "    \n",
    "    # Generate signals\n",
    "    shared_mod = 1 + 0.5 * np.sin(2 * np.pi * 0.3 * t)\n",
    "    indep_mod_x = 1 + 0.5 * np.sin(2 * np.pi * 0.4 * t + np.random.uniform(0, 2*np.pi))\n",
    "    indep_mod_y = 1 + 0.5 * np.sin(2 * np.pi * 0.5 * t + np.random.uniform(0, 2*np.pi))\n",
    "    \n",
    "    env_x = np.sqrt(amp_coupling) * shared_mod + np.sqrt(1-amp_coupling) * indep_mod_x\n",
    "    env_y = np.sqrt(amp_coupling) * shared_mod + np.sqrt(1-amp_coupling) * indep_mod_y\n",
    "    \n",
    "    if phase_coupling > 0.5:\n",
    "        phase_lag = np.pi/4\n",
    "    else:\n",
    "        phase_lag = np.random.uniform(0, 2*np.pi)\n",
    "    \n",
    "    x = env_x * np.sin(2 * np.pi * 10 * t) + 0.2 * np.random.randn(n_samples)\n",
    "    y = env_y * np.sin(2 * np.pi * 10 * t + phase_lag) + 0.2 * np.random.randn(n_samples)\n",
    "    \n",
    "    metrics = compute_all_connectivity_metrics(x, y, fs, band)\n",
    "    \n",
    "    all_results['PLV'].append(metrics['plv'])\n",
    "    all_results['PLI'].append(metrics['pli'])\n",
    "    all_results['wPLI'].append(metrics['wpli'])\n",
    "    all_results['CCorr'].append(metrics['ccorr'])\n",
    "    all_results['CCorr-orth'].append(metrics['ccorr_orth'])\n",
    "    all_results['PowCorr'].append(metrics['powcorr'])\n",
    "    all_results['PowCorr-orth'].append(metrics['powcorr_orth'])\n",
    "\n",
    "# Compute correlation matrix\n",
    "metric_corr = np.zeros((7, 7))\n",
    "for i, name_i in enumerate(metric_names):\n",
    "    for j, name_j in enumerate(metric_names):\n",
    "        metric_corr[i, j] = np.corrcoef(all_results[name_i], all_results[name_j])[0, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 8))\n",
    "\n",
    "im = ax.imshow(metric_corr, cmap='RdBu_r', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "# Add values\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        color = 'white' if abs(metric_corr[i, j]) > 0.5 else 'black'\n",
    "        ax.text(j, i, f'{metric_corr[i, j]:.2f}', ha='center', va='center', \n",
    "                fontsize=9, color=color, fontweight='bold')\n",
    "\n",
    "ax.set_xticks(range(7))\n",
    "ax.set_yticks(range(7))\n",
    "ax.set_xticklabels(metric_names, rotation=45, ha='right', fontsize=10)\n",
    "ax.set_yticklabels(metric_names, fontsize=10)\n",
    "\n",
    "# Group separators\n",
    "ax.axhline(2.5, color='black', linewidth=2)\n",
    "ax.axvline(2.5, color='black', linewidth=2)\n",
    "\n",
    "ax.set_title('Relationships Between Connectivity Metrics\\n'\n",
    "             '(Phase metrics cluster; Amplitude metrics cluster)', fontsize=13, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax, shrink=0.8, label='Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Key observations:\")\n",
    "print(\"   - Phase metrics (PLV, PLI, wPLI) correlate with each other\")\n",
    "print(\"   - Amplitude metrics (CCorr, PowCorr) correlate with each other\")\n",
    "print(\"   - Phase and amplitude show weaker cross-correlation\")\n",
    "print(\"   - They capture DIFFERENT aspects of connectivity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 11: Hands-On Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Power Correlation Basics\n",
    "# Generate signals with correlated power modulation\n",
    "# Compute instantaneous power correlation\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Exercise 1: Basic power correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Instantaneous vs Windowed\n",
    "# Compare both methods on the same signals\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Discuss: When would you prefer windowed over instantaneous?\n",
    "\n",
    "print(\"Exercise 2: Instantaneous vs windowed comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: CCorr vs PowCorr\n",
    "# Generate signals where the two metrics diverge\n",
    "# Hint: add low-amplitude noise\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Exercise 3: CCorr vs PowCorr divergence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Orthogonalization Check\n",
    "# Simulate volume conduction\n",
    "# Verify orthogonalized PowCorr is robust\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Exercise 4: Volume conduction test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Complete Metric Comparison\n",
    "# Create channel pairs with different connectivity types\n",
    "# Compute ALL metrics and interpret\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Exercise 5: Complete metric comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6: Hyperscanning Application\n",
    "# Compare CCorr and PowCorr for hyperscanning\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Which metric would you report and why?\n",
    "\n",
    "print(\"Exercise 6: Hyperscanning comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Power correlation**: Correlation of squared amplitude (power) time series\n",
    "   - Power = AÂ² emphasizes larger fluctuations\n",
    "   - Range: -1 to +1\n",
    "\n",
    "2. **Two approaches**:\n",
    "   - Instantaneous: continuous P(t), high temporal resolution\n",
    "   - Windowed: averaged power per epoch, more robust\n",
    "\n",
    "3. **Highly related to envelope correlation** â€” usually similar values\n",
    "   - PowCorr may be slightly more robust to low-amplitude noise\n",
    "\n",
    "4. **Orthogonalization** addresses volume conduction (like CCorr)\n",
    "\n",
    "5. **For hyperscanning**: Captures shared power fluctuations between participants\n",
    "\n",
    "6. **Choice**: CCorr is the standard; PowCorr is an alternative\n",
    "   - Always report which metric you used!\n",
    "\n",
    "7. **Complete toolkit now**:\n",
    "   - Phase: PLV, PLI, wPLI\n",
    "   - Amplitude: CCorr, CCorr-orth, PowCorr, PowCorr-orth\n",
    "   - Different metrics capture different aspects of connectivity!\n",
    "\n",
    "---\n",
    "\n",
    "## Discussion Questions\n",
    "\n",
    "1. In what scenarios would you expect envelope correlation and power correlation to give notably different results? What signal characteristics would drive this difference?\n",
    "\n",
    "2. You're designing a hyperscanning study and need to choose connectivity metrics. Would you compute both phase and amplitude metrics? How would you interpret results if they conflict?\n",
    "\n",
    "3. The literature mostly reports envelope correlation (AEC). Is there value in also reporting power correlation, or does it add unnecessary complexity?\n",
    "\n",
    "4. Power is AÂ². What about using log-power (dB) for correlation? Would this be more or less sensitive to large fluctuations? When might log-power correlation be useful?\n",
    "\n",
    "5. Looking across all the metrics covered in this workshop (PLV, PLI, wPLI, CCorr, PowCorr), which would you recommend as a \"default\" set for a new hyperscanning study? Justify your choices.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ‰ Workshop Complete!\n",
    "\n",
    "Congratulations! You've completed the hyperscanning connectivity metrics workshop. You now have a comprehensive toolkit for analyzing neural connectivity:\n",
    "\n",
    "**Phase-based metrics** (timing alignment):\n",
    "- PLV: Simple, high sensitivity\n",
    "- PLI: Volume conduction robust\n",
    "- wPLI: Robust to both VC and noise\n",
    "\n",
    "**Amplitude-based metrics** (strength co-modulation):\n",
    "- CCorr: Standard amplitude coupling\n",
    "- PowCorr: Power-based alternative\n",
    "- Orthogonalized versions for VC robustness\n",
    "\n",
    "**Remember**: These metrics capture *different* aspects of neural connectivity. Use them together for a complete picture!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
